<map id="mic::mlnn::Layer&lt; eT &gt;" name="mic::mlnn::Layer&lt; eT &gt;">
<area shape="rect" id="node2" href="$a00027.html" title="Class implementing the layer with Exponential Linear Unit (ELU). http://arxiv.org/pdf/1511.07289v5.pdf. " alt="" coords="229,5,377,46"/>
<area shape="rect" id="node3" href="$a00052.html" title="mic::mlnn::activation\l_function::ReLU\&lt; eT \&gt;" alt="" coords="225,70,381,111"/>
<area shape="rect" id="node4" href="$a00056.html" title="mic::mlnn::activation\l_function::Sigmoid\&lt; eT \&gt;" alt="" coords="218,135,387,177"/>
<area shape="rect" id="node5" href="$a00022.html" title="Class representing a convolution layer, with &quot;valid padding&quot; and variable stride. ..." alt="" coords="226,201,379,242"/>
<area shape="rect" id="node6" href="$a00023.html" title="Class implementing cropping operation &#45; crops the size of image (matrix) by a margin of n pixels on e..." alt="" coords="226,266,379,307"/>
<area shape="rect" id="node7" href="$a00042.html" title="Layer performing max pooling. " alt="" coords="226,331,379,373"/>
<area shape="rect" id="node8" href="$a00051.html" title="Class implementing padding operation &#45; expanding the size of image (matrix) by a margin of n pixels o..." alt="" coords="226,397,379,438"/>
<area shape="rect" id="node9" href="$a00058.html" title="Softmax activation function. " alt="" coords="220,462,385,503"/>
<area shape="rect" id="node10" href="$a00021.html" title="Class implementing a convolutional hebbian layer. " alt="" coords="222,527,383,569"/>
<area shape="rect" id="node11" href="$a00009.html" title="Class implementing a linear, fully connected layer. " alt="" coords="213,593,392,634"/>
<area shape="rect" id="node12" href="$a00030.html" title="Class implementing a linear, fully connected layer. " alt="" coords="213,658,392,699"/>
<area shape="rect" id="node13" href="$a00034.html" title="Class implementing a linear, fully connected layer. " alt="" coords="213,723,392,765"/>
<area shape="rect" id="node15" href="$a00026.html" title="Droput layer &#45; a layer used for the regularization of neural network by randomly dropping neurons dur..." alt="" coords="221,789,385,830"/>
<area shape="rect" id="node14" href="$a00060.html" title="Class implementing a linear, fully connected layer with sparsity regulation. " alt="" coords="440,723,619,765"/>
</map>
