<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.6"/>
<title>MachineIntelligenceCore:NeuralNets: mic::mlnn::Layer&lt; eT &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">MachineIntelligenceCore:NeuralNets
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.6 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
      <li><a href="inherits.html"><span>Class&#160;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&#160;Members</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('a00033.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Friends</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Macros</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="#pri-methods">Private Member Functions</a> &#124;
<a href="#friends">Friends</a> &#124;
<a href="a00332.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">mic::mlnn::Layer&lt; eT &gt; Class Template Reference<span class="mlabels"><span class="mlabel">abstract</span></span></div>  </div>
</div><!--header-->
<div class="contents">

<p><code>#include &lt;<a class="el" href="a00104_source.html">Layer.hpp</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for mic::mlnn::Layer&lt; eT &gt;:</div>
<div class="dyncontent">
<div class="center"><img src="a00333.png" border="0" usemap="#mic_1_1mlnn_1_1_layer_3_01e_t_01_4_inherit__map" alt="Inheritance graph"/></div>
<map name="mic_1_1mlnn_1_1_layer_3_01e_t_01_4_inherit__map" id="mic_1_1mlnn_1_1_layer_3_01e_t_01_4_inherit__map">
<area shape="rect" id="node2" href="a00027.html" title="Class implementing the layer with Exponential Linear Unit (ELU). http://arxiv.org/pdf/1511.07289v5.pdf. " alt="" coords="229,5,377,46"/><area shape="rect" id="node3" href="a00052.html" title="mic::mlnn::activation\l_function::ReLU\&lt; eT \&gt;" alt="" coords="225,70,381,111"/><area shape="rect" id="node4" href="a00056.html" title="mic::mlnn::activation\l_function::Sigmoid\&lt; eT \&gt;" alt="" coords="218,135,387,177"/><area shape="rect" id="node5" href="a00022.html" title="Class representing a convolution layer, with &quot;valid padding&quot; and variable stride. ..." alt="" coords="226,201,379,242"/><area shape="rect" id="node6" href="a00023.html" title="Class implementing cropping operation &#45; crops the size of image (matrix) by a margin of n pixels on e..." alt="" coords="226,266,379,307"/><area shape="rect" id="node7" href="a00042.html" title="Layer performing max pooling. " alt="" coords="226,331,379,373"/><area shape="rect" id="node8" href="a00051.html" title="Class implementing padding operation &#45; expanding the size of image (matrix) by a margin of n pixels o..." alt="" coords="226,397,379,438"/><area shape="rect" id="node9" href="a00058.html" title="Softmax activation function. " alt="" coords="220,462,385,503"/><area shape="rect" id="node10" href="a00021.html" title="Class implementing a convolutional hebbian layer. " alt="" coords="222,527,383,569"/><area shape="rect" id="node11" href="a00009.html" title="Class implementing a linear, fully connected layer. " alt="" coords="213,593,392,634"/><area shape="rect" id="node12" href="a00030.html" title="Class implementing a linear, fully connected layer. " alt="" coords="213,658,392,699"/><area shape="rect" id="node13" href="a00034.html" title="Class implementing a linear, fully connected layer. " alt="" coords="213,723,392,765"/><area shape="rect" id="node15" href="a00026.html" title="Droput layer &#45; a layer used for the regularization of neural network by randomly dropping neurons dur..." alt="" coords="221,789,385,830"/><area shape="rect" id="node14" href="a00060.html" title="Class implementing a linear, fully connected layer with sparsity regulation. " alt="" coords="440,723,619,765"/></map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for mic::mlnn::Layer&lt; eT &gt;:</div>
<div class="dyncontent">
<div class="center"><img src="a00334.png" border="0" usemap="#mic_1_1mlnn_1_1_layer_3_01e_t_01_4_coll__map" alt="Collaboration graph"/></div>
<map name="mic_1_1mlnn_1_1_layer_3_01e_t_01_4_coll__map" id="mic_1_1mlnn_1_1_layer_3_01e_t_01_4_coll__map">
<area shape="rect" id="node2" href="a00049.html" title="mic::neural_nets::optimization\l::OptimizationArray\&lt; eT \&gt;" alt="" coords="5,6,200,47"/></map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ab3f645c936f5b064ac479a0a7fbdb886"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#ab3f645c936f5b064ac479a0a7fbdb886">Layer</a> (size_t input_height_, size_t input_width_, size_t input_depth_, size_t output_height_, size_t output_width_, size_t output_depth_, <a class="el" href="a00153.html#a89105a145f4cf2ba1557d5e669a8a0f5">LayerTypes</a> layer_type_, std::string name_=&quot;layer&quot;)</td></tr>
<tr class="separator:ab3f645c936f5b064ac479a0a7fbdb886"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2f5db6881a38d27dc811c36c1123aabb"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a2f5db6881a38d27dc811c36c1123aabb">~Layer</a> ()</td></tr>
<tr class="separator:a2f5db6881a38d27dc811c36c1123aabb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1ae0acead237a96cf14f98c05eaa0093"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a1ae0acead237a96cf14f98c05eaa0093">forward</a> (bool test=false)=0</td></tr>
<tr class="separator:a1ae0acead237a96cf14f98c05eaa0093"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c966d2e7b471fe719d8d7126d549eed"><td class="memItemLeft" align="right" valign="top">mic::types::MatrixPtr&lt; eT &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a6c966d2e7b471fe719d8d7126d549eed">forward</a> (mic::types::MatrixPtr&lt; eT &gt; x_, bool test=false)</td></tr>
<tr class="separator:a6c966d2e7b471fe719d8d7126d549eed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8df6d39bce0eaa035c5751eac076b139"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a8df6d39bce0eaa035c5751eac076b139">backward</a> ()=0</td></tr>
<tr class="separator:a8df6d39bce0eaa035c5751eac076b139"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd40478a2725f90efceb8c7dad1ce27f"><td class="memItemLeft" align="right" valign="top">mic::types::MatrixPtr&lt; eT &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#acd40478a2725f90efceb8c7dad1ce27f">backward</a> (mic::types::MatrixPtr&lt; eT &gt; dy_)</td></tr>
<tr class="separator:acd40478a2725f90efceb8c7dad1ce27f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e8c95b39579783dd698f2bd104bd2ac"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a0e8c95b39579783dd698f2bd104bd2ac">resizeBatch</a> (size_t batch_size_)</td></tr>
<tr class="separator:a0e8c95b39579783dd698f2bd104bd2ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8208e78d7cb4b2fb8d4757f2c210a6c8"><td class="memTemplParams" colspan="2">template&lt;typename loss &gt; </td></tr>
<tr class="memitem:a8208e78d7cb4b2fb8d4757f2c210a6c8"><td class="memTemplItemLeft" align="right" valign="top">mic::types::MatrixPtr&lt; eT &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="a00033.html#a8208e78d7cb4b2fb8d4757f2c210a6c8">calculateNumericalGradient</a> (mic::types::MatrixPtr&lt; eT &gt; x_, mic::types::MatrixPtr&lt; eT &gt; target_y_, mic::types::MatrixPtr&lt; eT &gt; param_, loss loss_, eT delta_)</td></tr>
<tr class="separator:a8208e78d7cb4b2fb8d4757f2c210a6c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a65896623f0fd96cbc00fc1ac4cf5ed4d"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a65896623f0fd96cbc00fc1ac4cf5ed4d">resetGrads</a> ()</td></tr>
<tr class="separator:a65896623f0fd96cbc00fc1ac4cf5ed4d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afb1d1f61c2472d6cc3fce774df0b13c5"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#afb1d1f61c2472d6cc3fce774df0b13c5">update</a> (eT alpha_, eT decay_=0.0f)=0</td></tr>
<tr class="separator:afb1d1f61c2472d6cc3fce774df0b13c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeec074547484acb4de4124501fb10a58"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#aeec074547484acb4de4124501fb10a58">inputSize</a> ()</td></tr>
<tr class="memdesc:aeec074547484acb4de4124501fb10a58"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns size (length) of inputs.  <a href="#aeec074547484acb4de4124501fb10a58">More...</a><br/></td></tr>
<tr class="separator:aeec074547484acb4de4124501fb10a58"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c932ed1758edd3daf527bf99518e19c"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a2c932ed1758edd3daf527bf99518e19c">outputSize</a> ()</td></tr>
<tr class="memdesc:a2c932ed1758edd3daf527bf99518e19c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns size (length) of outputs.  <a href="#a2c932ed1758edd3daf527bf99518e19c">More...</a><br/></td></tr>
<tr class="separator:a2c932ed1758edd3daf527bf99518e19c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8bcf8f0debb8c3e1346bf1e01d951320"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a8bcf8f0debb8c3e1346bf1e01d951320">batchSize</a> ()</td></tr>
<tr class="memdesc:a8bcf8f0debb8c3e1346bf1e01d951320"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns size (length) of (mini)batch.  <a href="#a8bcf8f0debb8c3e1346bf1e01d951320">More...</a><br/></td></tr>
<tr class="separator:a8bcf8f0debb8c3e1346bf1e01d951320"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac39c21ffbcc21efd0282e67c28f95c30"><td class="memItemLeft" align="right" valign="top">const std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#ac39c21ffbcc21efd0282e67c28f95c30">name</a> () const </td></tr>
<tr class="memdesc:ac39c21ffbcc21efd0282e67c28f95c30"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns name of the layer.  <a href="#ac39c21ffbcc21efd0282e67c28f95c30">More...</a><br/></td></tr>
<tr class="separator:ac39c21ffbcc21efd0282e67c28f95c30"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9ecd21746d195133629292a6c85d5f3f"><td class="memItemLeft" align="right" valign="top">mic::types::MatrixPtr&lt; eT &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a9ecd21746d195133629292a6c85d5f3f">getParam</a> (std::string name_)</td></tr>
<tr class="separator:a9ecd21746d195133629292a6c85d5f3f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a03586b6b1863bb3f88cdb1aecf630bd3"><td class="memItemLeft" align="right" valign="top">mic::types::MatrixPtr&lt; eT &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a03586b6b1863bb3f88cdb1aecf630bd3">getState</a> (std::string name_)</td></tr>
<tr class="separator:a03586b6b1863bb3f88cdb1aecf630bd3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac3b7c9e99d0c32e040779ed27f18bf93"><td class="memItemLeft" align="right" valign="top">mic::types::MatrixPtr&lt; eT &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#ac3b7c9e99d0c32e040779ed27f18bf93">getGradient</a> (std::string name_)</td></tr>
<tr class="separator:ac3b7c9e99d0c32e040779ed27f18bf93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaa9f2ac12b09f7cb90ccc4587cd9ea10"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#aaa9f2ac12b09f7cb90ccc4587cd9ea10">setState</a> (std::string name_, mic::types::MatrixPtr&lt; eT &gt; mat_ptr_)</td></tr>
<tr class="separator:aaa9f2ac12b09f7cb90ccc4587cd9ea10"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae092b4068aee4967556bcba9ff4b81fe"><td class="memTemplParams" colspan="2">template&lt;typename omT &gt; </td></tr>
<tr class="memitem:ae092b4068aee4967556bcba9ff4b81fe"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="a00033.html#ae092b4068aee4967556bcba9ff4b81fe">setOptimization</a> ()</td></tr>
<tr class="separator:ae092b4068aee4967556bcba9ff4b81fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a596aeefd90b3bead3f6db8fdeb1ef1ce"><td class="memItemLeft" align="right" valign="top">const std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a596aeefd90b3bead3f6db8fdeb1ef1ce">type</a> () const </td></tr>
<tr class="separator:a596aeefd90b3bead3f6db8fdeb1ef1ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d8d9bd174b1c243426eff80c6138f26"><td class="memItemLeft" align="right" valign="top">virtual std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a5d8d9bd174b1c243426eff80c6138f26">streamLayerParameters</a> ()</td></tr>
<tr class="separator:a5d8d9bd174b1c243426eff80c6138f26"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18a50dcf6752cd55b80f7a6f1a9defff"><td class="memItemLeft" align="right" valign="top">mic::types::MatrixPtr&lt; eT &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a18a50dcf6752cd55b80f7a6f1a9defff">lazyReturnSampleFromBatch</a> (mic::types::MatrixPtr&lt; eT &gt; batch_ptr_, mic::types::MatrixArray&lt; eT &gt; &amp;array_, std::string id_, size_t sample_number_, size_t sample_size_)</td></tr>
<tr class="separator:a18a50dcf6752cd55b80f7a6f1a9defff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a76225cc40fc1aa81607fea6430e398b2"><td class="memItemLeft" align="right" valign="top">mic::types::MatrixPtr&lt; eT &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a76225cc40fc1aa81607fea6430e398b2">lazyReturnInputSample</a> (mic::types::MatrixPtr&lt; eT &gt; batch_ptr_, size_t sample_number_)</td></tr>
<tr class="separator:a76225cc40fc1aa81607fea6430e398b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add6a26e84e77d387b8fcdadd9f7c85cf"><td class="memItemLeft" align="right" valign="top">mic::types::MatrixPtr&lt; eT &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#add6a26e84e77d387b8fcdadd9f7c85cf">lazyReturnOutputSample</a> (mic::types::MatrixPtr&lt; eT &gt; batch_ptr_, size_t sample_number_)</td></tr>
<tr class="separator:add6a26e84e77d387b8fcdadd9f7c85cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a209b8398e28c682e63c895e2cac56507"><td class="memItemLeft" align="right" valign="top">mic::types::MatrixPtr&lt; eT &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a209b8398e28c682e63c895e2cac56507">lazyReturnChannelFromSample</a> (mic::types::MatrixPtr&lt; eT &gt; sample_ptr_, mic::types::MatrixArray&lt; eT &gt; &amp;array_, std::string id_, size_t sample_number_, size_t channel_number_, size_t height_, size_t width_)</td></tr>
<tr class="separator:a209b8398e28c682e63c895e2cac56507"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9ca3c12d05180ea01c604e0194f7b96f"><td class="memItemLeft" align="right" valign="top">mic::types::MatrixPtr&lt; eT &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a9ca3c12d05180ea01c604e0194f7b96f">lazyReturnInputChannel</a> (mic::types::MatrixPtr&lt; eT &gt; sample_ptr_, size_t sample_number_, size_t channel_number_)</td></tr>
<tr class="separator:a9ca3c12d05180ea01c604e0194f7b96f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad09e0efe88899effc76308dc526b6074"><td class="memItemLeft" align="right" valign="top">mic::types::MatrixPtr&lt; eT &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#ad09e0efe88899effc76308dc526b6074">lazyReturnOutputChannel</a> (mic::types::MatrixPtr&lt; eT &gt; sample_ptr_, size_t sample_number_, size_t channel_number_)</td></tr>
<tr class="separator:ad09e0efe88899effc76308dc526b6074"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3ae69529f23d218b9fcad614e38d33e4"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a3ae69529f23d218b9fcad614e38d33e4">lazyAllocateMatrixVector</a> (std::vector&lt; std::shared_ptr&lt; mic::types::Matrix&lt; eT &gt; &gt; &gt; &amp;vector_, size_t vector_size_, size_t matrix_height_, size_t matrix_width_)</td></tr>
<tr class="separator:a3ae69529f23d218b9fcad614e38d33e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1395a837544f1c1a21523b5c34fdff7e"><td class="memItemLeft" align="right" valign="top">virtual std::vector<br class="typebreak"/>
&lt; std::shared_ptr<br class="typebreak"/>
&lt; mic::types::Matrix&lt; eT &gt; &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a1395a837544f1c1a21523b5c34fdff7e">getInputActivations</a> ()</td></tr>
<tr class="separator:a1395a837544f1c1a21523b5c34fdff7e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2bff358c7554f70607d1478e9cdc9e66"><td class="memItemLeft" align="right" valign="top">virtual std::vector<br class="typebreak"/>
&lt; std::shared_ptr<br class="typebreak"/>
&lt; mic::types::Matrix&lt; eT &gt; &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a2bff358c7554f70607d1478e9cdc9e66">getInputGradientActivations</a> ()</td></tr>
<tr class="separator:a2bff358c7554f70607d1478e9cdc9e66"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7faa89421e83920207accfc9a207e416"><td class="memItemLeft" align="right" valign="top">virtual std::vector<br class="typebreak"/>
&lt; std::shared_ptr<br class="typebreak"/>
&lt; mic::types::Matrix&lt; eT &gt; &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a7faa89421e83920207accfc9a207e416">getOutputActivations</a> ()</td></tr>
<tr class="separator:a7faa89421e83920207accfc9a207e416"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae179222d8ba936b7ea96b0291d1b8066"><td class="memItemLeft" align="right" valign="top">virtual std::vector<br class="typebreak"/>
&lt; std::shared_ptr<br class="typebreak"/>
&lt; mic::types::Matrix&lt; eT &gt; &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#ae179222d8ba936b7ea96b0291d1b8066">getOutputGradientActivations</a> ()</td></tr>
<tr class="separator:ae179222d8ba936b7ea96b0291d1b8066"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:a9f2ca865ff5327bf892bb13a69139a78"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a9f2ca865ff5327bf892bb13a69139a78">Layer</a> ()</td></tr>
<tr class="separator:a9f2ca865ff5327bf892bb13a69139a78"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:a30ee8b10b8c7425e6c987359b7bbf8fc"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a30ee8b10b8c7425e6c987359b7bbf8fc">input_height</a></td></tr>
<tr class="memdesc:a30ee8b10b8c7425e6c987359b7bbf8fc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Height of the input (e.g. 28 for MNIST).  <a href="#a30ee8b10b8c7425e6c987359b7bbf8fc">More...</a><br/></td></tr>
<tr class="separator:a30ee8b10b8c7425e6c987359b7bbf8fc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9789ac1e5becaef7a112f069bd63a957"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a9789ac1e5becaef7a112f069bd63a957">input_width</a></td></tr>
<tr class="memdesc:a9789ac1e5becaef7a112f069bd63a957"><td class="mdescLeft">&#160;</td><td class="mdescRight">Width of the input (e.g. 28 for MNIST).  <a href="#a9789ac1e5becaef7a112f069bd63a957">More...</a><br/></td></tr>
<tr class="separator:a9789ac1e5becaef7a112f069bd63a957"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a051e607097e1b8491ceab635a1105ff6"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a051e607097e1b8491ceab635a1105ff6">input_depth</a></td></tr>
<tr class="memdesc:a051e607097e1b8491ceab635a1105ff6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of channels of the input (e.g. 3 for RGB images).  <a href="#a051e607097e1b8491ceab635a1105ff6">More...</a><br/></td></tr>
<tr class="separator:a051e607097e1b8491ceab635a1105ff6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a97d292eb9f57fc8a55b824ca03dd2bf6"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a97d292eb9f57fc8a55b824ca03dd2bf6">output_height</a></td></tr>
<tr class="memdesc:a97d292eb9f57fc8a55b824ca03dd2bf6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of receptive fields in a single channel - vertical direction.  <a href="#a97d292eb9f57fc8a55b824ca03dd2bf6">More...</a><br/></td></tr>
<tr class="separator:a97d292eb9f57fc8a55b824ca03dd2bf6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af557b9cb28961ea3a6e0f8bd7159f108"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#af557b9cb28961ea3a6e0f8bd7159f108">output_width</a></td></tr>
<tr class="memdesc:af557b9cb28961ea3a6e0f8bd7159f108"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of receptive fields in a single channel - horizontal direction.  <a href="#af557b9cb28961ea3a6e0f8bd7159f108">More...</a><br/></td></tr>
<tr class="separator:af557b9cb28961ea3a6e0f8bd7159f108"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42ae81a0beee2d26d67eee2333f24679"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a42ae81a0beee2d26d67eee2333f24679">output_depth</a></td></tr>
<tr class="memdesc:a42ae81a0beee2d26d67eee2333f24679"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of filters = number of output channels.  <a href="#a42ae81a0beee2d26d67eee2333f24679">More...</a><br/></td></tr>
<tr class="separator:a42ae81a0beee2d26d67eee2333f24679"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af8f8cecebc159b6bbecab3dd1a962652"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#af8f8cecebc159b6bbecab3dd1a962652">batch_size</a></td></tr>
<tr class="memdesc:af8f8cecebc159b6bbecab3dd1a962652"><td class="mdescLeft">&#160;</td><td class="mdescRight">Size (length) of (mini)batch.  <a href="#af8f8cecebc159b6bbecab3dd1a962652">More...</a><br/></td></tr>
<tr class="separator:af8f8cecebc159b6bbecab3dd1a962652"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b5806d64072a7882f21ed7cf1ddffb2"><td class="memItemLeft" align="right" valign="top"><a class="el" href="a00153.html#a89105a145f4cf2ba1557d5e669a8a0f5">LayerTypes</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a6b5806d64072a7882f21ed7cf1ddffb2">layer_type</a></td></tr>
<tr class="memdesc:a6b5806d64072a7882f21ed7cf1ddffb2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Type of the layer.  <a href="#a6b5806d64072a7882f21ed7cf1ddffb2">More...</a><br/></td></tr>
<tr class="separator:a6b5806d64072a7882f21ed7cf1ddffb2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a289e418de1cf2e2582b99d9d9f19cc02"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a289e418de1cf2e2582b99d9d9f19cc02">layer_name</a></td></tr>
<tr class="memdesc:a289e418de1cf2e2582b99d9d9f19cc02"><td class="mdescLeft">&#160;</td><td class="mdescRight">Name (identifier of the type) of the layer.  <a href="#a289e418de1cf2e2582b99d9d9f19cc02">More...</a><br/></td></tr>
<tr class="separator:a289e418de1cf2e2582b99d9d9f19cc02"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca73ce8b130d8e5996aad367d6c86d48"><td class="memItemLeft" align="right" valign="top">mic::types::MatrixArray&lt; eT &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#aca73ce8b130d8e5996aad367d6c86d48">s</a></td></tr>
<tr class="memdesc:aca73ce8b130d8e5996aad367d6c86d48"><td class="mdescLeft">&#160;</td><td class="mdescRight">States - contains input [x] and output [y] matrices.  <a href="#aca73ce8b130d8e5996aad367d6c86d48">More...</a><br/></td></tr>
<tr class="separator:aca73ce8b130d8e5996aad367d6c86d48"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca32d9cfff631e2c529f469647a90570"><td class="memItemLeft" align="right" valign="top">mic::types::MatrixArray&lt; eT &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#aca32d9cfff631e2c529f469647a90570">g</a></td></tr>
<tr class="memdesc:aca32d9cfff631e2c529f469647a90570"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gradients - contains input [x] and output [y] matrices.  <a href="#aca32d9cfff631e2c529f469647a90570">More...</a><br/></td></tr>
<tr class="separator:aca32d9cfff631e2c529f469647a90570"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac06ea0597a86992a70429e4926504f01"><td class="memItemLeft" align="right" valign="top">mic::types::MatrixArray&lt; eT &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#ac06ea0597a86992a70429e4926504f01">p</a></td></tr>
<tr class="memdesc:ac06ea0597a86992a70429e4926504f01"><td class="mdescLeft">&#160;</td><td class="mdescRight">Parameters - parameters of the layer, to be used by the derived classes.  <a href="#ac06ea0597a86992a70429e4926504f01">More...</a><br/></td></tr>
<tr class="separator:ac06ea0597a86992a70429e4926504f01"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af591178808a0b219eb6c42666872db24"><td class="memItemLeft" align="right" valign="top">mic::types::MatrixArray&lt; eT &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#af591178808a0b219eb6c42666872db24">m</a></td></tr>
<tr class="memdesc:af591178808a0b219eb6c42666872db24"><td class="mdescLeft">&#160;</td><td class="mdescRight">Memory - a list of temporal parameters, to be used by the derived classes.  <a href="#af591178808a0b219eb6c42666872db24">More...</a><br/></td></tr>
<tr class="separator:af591178808a0b219eb6c42666872db24"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75b903652bcbb62dfb22be34af7e0c8e"><td class="memItemLeft" align="right" valign="top"><a class="el" href="a00049.html">mic::neural_nets::optimization::OptimizationArray</a><br class="typebreak"/>
&lt; eT &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a75b903652bcbb62dfb22be34af7e0c8e">opt</a></td></tr>
<tr class="memdesc:a75b903652bcbb62dfb22be34af7e0c8e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Array of optimization functions.  <a href="#a75b903652bcbb62dfb22be34af7e0c8e">More...</a><br/></td></tr>
<tr class="separator:a75b903652bcbb62dfb22be34af7e0c8e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a041b6dd9d22f6571f7e472e650935643"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::shared_ptr<br class="typebreak"/>
&lt; mic::types::Matrix&lt; eT &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a041b6dd9d22f6571f7e472e650935643">x_activations</a></td></tr>
<tr class="memdesc:a041b6dd9d22f6571f7e472e650935643"><td class="mdescLeft">&#160;</td><td class="mdescRight">Vector containing activations of input neurons - used in visualization.  <a href="#a041b6dd9d22f6571f7e472e650935643">More...</a><br/></td></tr>
<tr class="separator:a041b6dd9d22f6571f7e472e650935643"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a953514d3d0a642bdb64df6d79f33d277"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::shared_ptr<br class="typebreak"/>
&lt; mic::types::Matrix&lt; eT &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a953514d3d0a642bdb64df6d79f33d277">dx_activations</a></td></tr>
<tr class="memdesc:a953514d3d0a642bdb64df6d79f33d277"><td class="mdescLeft">&#160;</td><td class="mdescRight">Vector containing activations of gradients of inputs (dx) - used in visualization.  <a href="#a953514d3d0a642bdb64df6d79f33d277">More...</a><br/></td></tr>
<tr class="separator:a953514d3d0a642bdb64df6d79f33d277"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add0b5a4df52eb24e75d3a98395efae95"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::shared_ptr<br class="typebreak"/>
&lt; mic::types::Matrix&lt; eT &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#add0b5a4df52eb24e75d3a98395efae95">y_activations</a></td></tr>
<tr class="memdesc:add0b5a4df52eb24e75d3a98395efae95"><td class="mdescLeft">&#160;</td><td class="mdescRight">Vector containing activations of output neurons - used in visualization.  <a href="#add0b5a4df52eb24e75d3a98395efae95">More...</a><br/></td></tr>
<tr class="separator:add0b5a4df52eb24e75d3a98395efae95"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8033474a7f1821f682e0ee347b8ad221"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::shared_ptr<br class="typebreak"/>
&lt; mic::types::Matrix&lt; eT &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a8033474a7f1821f682e0ee347b8ad221">dy_activations</a></td></tr>
<tr class="memdesc:a8033474a7f1821f682e0ee347b8ad221"><td class="mdescLeft">&#160;</td><td class="mdescRight">Vector containing activations of gradients of outputs (dy) - used in visualization.  <a href="#a8033474a7f1821f682e0ee347b8ad221">More...</a><br/></td></tr>
<tr class="separator:a8033474a7f1821f682e0ee347b8ad221"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pri-methods"></a>
Private Member Functions</h2></td></tr>
<tr class="memitem:ab8f6c594af8da63691e1a52ebe4f5abf"><td class="memTemplParams" colspan="2">template&lt;class Archive &gt; </td></tr>
<tr class="memitem:ab8f6c594af8da63691e1a52ebe4f5abf"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="a00033.html#ab8f6c594af8da63691e1a52ebe4f5abf">serialize</a> (Archive &amp;ar, const unsigned int version)</td></tr>
<tr class="separator:ab8f6c594af8da63691e1a52ebe4f5abf"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="friends"></a>
Friends</h2></td></tr>
<tr class="memitem:aa969764c5ebc6981d59d283733539c8b"><td class="memTemplParams" colspan="2">template&lt;typename tmp &gt; </td></tr>
<tr class="memitem:aa969764c5ebc6981d59d283733539c8b"><td class="memTemplItemLeft" align="right" valign="top">class&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="a00033.html#aa969764c5ebc6981d59d283733539c8b">MultiLayerNeuralNetwork</a></td></tr>
<tr class="separator:aa969764c5ebc6981d59d283733539c8b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa365e3ee8444539572b26ddf4555c688"><td class="memTemplParams" colspan="2">template&lt;typename tmp &gt; </td></tr>
<tr class="memitem:aa365e3ee8444539572b26ddf4555c688"><td class="memTemplItemLeft" align="right" valign="top">class&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="a00033.html#aa365e3ee8444539572b26ddf4555c688">BackpropagationNeuralNetwork</a></td></tr>
<tr class="separator:aa365e3ee8444539572b26ddf4555c688"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d5de6e8e333572b800e9bf5822ed565"><td class="memTemplParams" colspan="2">template&lt;typename tmp &gt; </td></tr>
<tr class="memitem:a7d5de6e8e333572b800e9bf5822ed565"><td class="memTemplItemLeft" align="right" valign="top">class&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="a00033.html#a7d5de6e8e333572b800e9bf5822ed565">HebbianNeuralNetwork</a></td></tr>
<tr class="separator:a7d5de6e8e333572b800e9bf5822ed565"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac98d07dd8f7b70e16ccb9a01abf56b9c"><td class="memItemLeft" align="right" valign="top">class&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#ac98d07dd8f7b70e16ccb9a01abf56b9c">boost::serialization::access</a></td></tr>
<tr class="separator:ac98d07dd8f7b70e16ccb9a01abf56b9c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5305245ebe24302b2a87eac1fd8792d6"><td class="memItemLeft" align="right" valign="top">std::ostream &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="a00033.html#a5305245ebe24302b2a87eac1fd8792d6">operator&lt;&lt;</a> (std::ostream &amp;os_, <a class="el" href="a00033.html">Layer</a> &amp;obj_)</td></tr>
<tr class="separator:a5305245ebe24302b2a87eac1fd8792d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3>template&lt;typename eT = float&gt;<br/>
class mic::mlnn::Layer&lt; eT &gt;</h3>

<p>Template base (abstract) class representing a layer. </p>
<dl class="section author"><dt>Author</dt><dd>tkornuta/krocki </dd></dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">eT</td><td>Template parameter denoting precision of variables (float for calculations/double for testing). </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="a00104_source.html#l00094">94</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a class="anchor" id="ab3f645c936f5b064ac479a0a7fbdb886"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::<a class="el" href="a00033.html">Layer</a> </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>input_height_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>input_width_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>input_depth_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>output_height_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>output_width_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>output_depth_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="a00153.html#a89105a145f4cf2ba1557d5e669a8a0f5">LayerTypes</a>&#160;</td>
          <td class="paramname"><em>layer_type_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>name_</em> = <code>&quot;layer&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Default constructor of the layer parent class. Sets the input-output dimensions, layer type and name. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input_height_</td><td>Height of the input sample. </td></tr>
    <tr><td class="paramname">input_width_</td><td>Width of the input sample. </td></tr>
    <tr><td class="paramname">input_depth_</td><td>Depth of the input sample. </td></tr>
    <tr><td class="paramname">output_height_</td><td>Width of the output sample. </td></tr>
    <tr><td class="paramname">output_width_</td><td>Height of the output sample. </td></tr>
    <tr><td class="paramname">output_depth_</td><td>Depth of the output sample. </td></tr>
    <tr><td class="paramname">layer_type_</td><td>Type of the layer. </td></tr>
    <tr><td class="paramname">name_</td><td>Name of the layer. </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="a00104_source.html#l00107">107</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a2f5db6881a38d27dc811c36c1123aabb"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::~<a class="el" href="a00033.html">Layer</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Virtual destructor - required for the correct destruction of objects of derived classes. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00154">154</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a9f2ca865ff5327bf892bb13a69139a78"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::<a class="el" href="a00033.html">Layer</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Protected constructor, used only by the derived classes during the serialization. Empty!! </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00783">783</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a class="anchor" id="a8df6d39bce0eaa035c5751eac076b139"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::backward </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Abstract method responsible for processing the gradients from outputs to inputs (i.e. in the opposite direction). To be overridden in the derived classes. </p>

<p>Implemented in <a class="el" href="a00022.html#a12396f2615b8acbf866be96fa5ce6b81">mic::mlnn::convolution::Convolution&lt; eT &gt;</a>, <a class="el" href="a00022.html#a12396f2615b8acbf866be96fa5ce6b81">mic::mlnn::convolution::Convolution&lt; double &gt;</a>, <a class="el" href="a00022.html#a12396f2615b8acbf866be96fa5ce6b81">mic::mlnn::convolution::Convolution&lt; float &gt;</a>, <a class="el" href="a00042.html#a77437e3f00f0a426166c855d5c785ffe">mic::mlnn::convolution::MaxPooling&lt; eT &gt;</a>, <a class="el" href="a00034.html#aa3e3c73924a42243c87cb43bf77389bb">mic::mlnn::fully_connected::Linear&lt; eT &gt;</a>, <a class="el" href="a00034.html#aa3e3c73924a42243c87cb43bf77389bb">mic::mlnn::fully_connected::Linear&lt; double &gt;</a>, <a class="el" href="a00034.html#aa3e3c73924a42243c87cb43bf77389bb">mic::mlnn::fully_connected::Linear&lt; float &gt;</a>, <a class="el" href="a00009.html#a624e26896a6c9ddd8296bf0a38b89e00">mic::mlnn::fully_connected::BinaryCorrelator&lt; eT &gt;</a>, <a class="el" href="a00058.html#a7ee9cf41698f2857eb7e174b61bcf69a">mic::mlnn::cost_function::Softmax&lt; eT &gt;</a>, <a class="el" href="a00058.html#a7ee9cf41698f2857eb7e174b61bcf69a">mic::mlnn::cost_function::Softmax&lt; float &gt;</a>, <a class="el" href="a00030.html#aed27191a7173b65bae8788a048f29890">mic::mlnn::fully_connected::HebbianLinear&lt; eT &gt;</a>, <a class="el" href="a00051.html#aa94647754934795dda6adf7ea023ce10">mic::mlnn::convolution::Padding&lt; eT &gt;</a>, <a class="el" href="a00021.html#a2cfb69d243370f88fd12056da386dd5e">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;</a>, <a class="el" href="a00023.html#a6bc80b70441dc103ab6307f12ec3a554">mic::mlnn::convolution::Cropping&lt; eT &gt;</a>, <a class="el" href="a00026.html#aa4c395982884a1cf89e477b1680c4b78">mic::mlnn::regularisation::Dropout&lt; eT &gt;</a>, <a class="el" href="a00052.html#a01fd66b0ffd7359058e4b56c41c26910">mic::mlnn::activation_function::ReLU&lt; eT &gt;</a>, <a class="el" href="a00027.html#a8d99295c3ff416b40aa01c09a5d798cf">mic::mlnn::activation_function::ELU&lt; eT &gt;</a>, <a class="el" href="a00056.html#abba98ccb53cb887b0dd01bff97ecf280">mic::mlnn::activation_function::Sigmoid&lt; eT &gt;</a>, and <a class="el" href="a00060.html#a72ae0e39579013fc17a7d29475497f6b">mic::mlnn::fully_connected::SparseLinear&lt; eT &gt;</a>.</p>

<p>Referenced by <a class="el" href="a00104_source.html#l00184">mic::mlnn::Layer&lt; float &gt;::backward()</a>.</p>

</div>
</div>
<a class="anchor" id="acd40478a2725f90efceb8c7dad1ce27f"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">mic::types::MatrixPtr&lt;eT&gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::backward </td>
          <td>(</td>
          <td class="paramtype">mic::types::MatrixPtr&lt; eT &gt;&#160;</td>
          <td class="paramname"><em>dy_</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Backward pass - backpropagation. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00184">184</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a8bcf8f0debb8c3e1346bf1e01d951320"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::batchSize </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns size (length) of (mini)batch. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00265">265</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a8208e78d7cb4b2fb8d4757f2c210a6c8"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<div class="memtemplate">
template&lt;typename loss &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">mic::types::MatrixPtr&lt;eT&gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::calculateNumericalGradient </td>
          <td>(</td>
          <td class="paramtype">mic::types::MatrixPtr&lt; eT &gt;&#160;</td>
          <td class="paramname"><em>x_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">mic::types::MatrixPtr&lt; eT &gt;&#160;</td>
          <td class="paramname"><em>target_y_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">mic::types::MatrixPtr&lt; eT &gt;&#160;</td>
          <td class="paramname"><em>param_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">loss&#160;</td>
          <td class="paramname"><em>loss_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">eT&#160;</td>
          <td class="paramname"><em>delta_</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Calculates the numerical gradient. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x_</td><td>Input vector. </td></tr>
    <tr><td class="paramname">target_y_</td><td>Target (desired) output. </td></tr>
    <tr><td class="paramname">loss_</td><td>Loss function. </td></tr>
    <tr><td class="paramname">delta_</td><td>Delta. </td></tr>
  </table>
  </dd>
</dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">loss</td><td>Loss function type. </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="a00104_source.html#l00219">219</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a1ae0acead237a96cf14f98c05eaa0093"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::forward </td>
          <td>(</td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>test</em> = <code>false</code></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Abstract method responsible for processing the data from the inputs to outputs. To be overridden in the derived classes. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">test</td><td>Test mode - used for dropout-alike regularization techniques. </td></tr>
  </table>
  </dd>
</dl>

<p>Implemented in <a class="el" href="a00022.html#a6009ea498721423544827e6f71954e26">mic::mlnn::convolution::Convolution&lt; eT &gt;</a>, <a class="el" href="a00022.html#a6009ea498721423544827e6f71954e26">mic::mlnn::convolution::Convolution&lt; double &gt;</a>, <a class="el" href="a00022.html#a6009ea498721423544827e6f71954e26">mic::mlnn::convolution::Convolution&lt; float &gt;</a>, <a class="el" href="a00009.html#ad4fea02897a52ebcf18359665a0b46d7">mic::mlnn::fully_connected::BinaryCorrelator&lt; eT &gt;</a>, <a class="el" href="a00034.html#ae8d300f1844bef707129f3d38de2583a">mic::mlnn::fully_connected::Linear&lt; eT &gt;</a>, <a class="el" href="a00034.html#ae8d300f1844bef707129f3d38de2583a">mic::mlnn::fully_connected::Linear&lt; double &gt;</a>, <a class="el" href="a00034.html#ae8d300f1844bef707129f3d38de2583a">mic::mlnn::fully_connected::Linear&lt; float &gt;</a>, <a class="el" href="a00030.html#a2e1c8e59c00c09bdbc0629622c2e9f37">mic::mlnn::fully_connected::HebbianLinear&lt; eT &gt;</a>, <a class="el" href="a00058.html#a41ad15a456e998e1b9dd9cabd301c86d">mic::mlnn::cost_function::Softmax&lt; eT &gt;</a>, <a class="el" href="a00058.html#a41ad15a456e998e1b9dd9cabd301c86d">mic::mlnn::cost_function::Softmax&lt; float &gt;</a>, <a class="el" href="a00021.html#aaf80ba09a855a40f50ec2c8cd87e6051">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;</a>, <a class="el" href="a00042.html#aa611cec53986b54c3c5b71d804e4788e">mic::mlnn::convolution::MaxPooling&lt; eT &gt;</a>, <a class="el" href="a00027.html#aa35b477ecae8e244339eac007346bc3b">mic::mlnn::activation_function::ELU&lt; eT &gt;</a>, <a class="el" href="a00052.html#a3b7d81b059629556282b6148645c12b8">mic::mlnn::activation_function::ReLU&lt; eT &gt;</a>, <a class="el" href="a00056.html#a888c87d9c582f224aab937b47de72763">mic::mlnn::activation_function::Sigmoid&lt; eT &gt;</a>, <a class="el" href="a00026.html#a73cbe006109c6c123cab55d02f2141e4">mic::mlnn::regularisation::Dropout&lt; eT &gt;</a>, <a class="el" href="a00023.html#a95e6d6a7eaf41880e2d0c2730557900e">mic::mlnn::convolution::Cropping&lt; eT &gt;</a>, and <a class="el" href="a00051.html#a83004534e5cb5edcd8d95b4a1a360c50">mic::mlnn::convolution::Padding&lt; eT &gt;</a>.</p>

<p>Referenced by <a class="el" href="a00104_source.html#l00219">mic::mlnn::Layer&lt; float &gt;::calculateNumericalGradient()</a>, and <a class="el" href="a00104_source.html#l00165">mic::mlnn::Layer&lt; float &gt;::forward()</a>.</p>

</div>
</div>
<a class="anchor" id="a6c966d2e7b471fe719d8d7126d549eed"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">mic::types::MatrixPtr&lt;eT&gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::forward </td>
          <td>(</td>
          <td class="paramtype">mic::types::MatrixPtr&lt; eT &gt;&#160;</td>
          <td class="paramname"><em>x_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>test</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Forwards the activations of the neural network. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00165">165</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="ac3b7c9e99d0c32e040779ed27f18bf93"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">mic::types::MatrixPtr&lt;eT&gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::getGradient </td>
          <td>(</td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>name_</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Returns the pointer to gradient (matrix) (or throws an exception!) </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00291">291</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a1395a837544f1c1a21523b5c34fdff7e"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual std::vector&lt; std::shared_ptr &lt;mic::types::Matrix&lt;eT&gt; &gt; &gt;&amp; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::getInputActivations </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Normalizes the matrix. to the range &lt;-1.0, 1.0&gt;, e.g. for the visualization purposes. DEPRICATED - functionality moved to mi-visualization! </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">matrix_</td><td>Matrix to be normalized.</td></tr>
  </table>
  </dd>
</dl>
<p>Returns activations of input neurons. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00586">586</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a2bff358c7554f70607d1478e9cdc9e66"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual std::vector&lt; std::shared_ptr &lt;mic::types::Matrix&lt;eT&gt; &gt; &gt;&amp; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::getInputGradientActivations </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Returns activations of input gradients (dx). </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00621">621</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a7faa89421e83920207accfc9a207e416"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual std::vector&lt; std::shared_ptr &lt;mic::types::Matrix&lt;eT&gt; &gt; &gt;&amp; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::getOutputActivations </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Returns activations of output neurons. </p>

<p>Reimplemented in <a class="el" href="a00021.html#ad0cbb2ab2e1258cc7605c091ece7b1fe">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;</a>.</p>

<p>Definition at line <a class="el" href="a00104_source.html#l00656">656</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="ae179222d8ba936b7ea96b0291d1b8066"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual std::vector&lt; std::shared_ptr &lt;mic::types::Matrix&lt;eT&gt; &gt; &gt;&amp; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::getOutputGradientActivations </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Returns activations of gradients of output neurons. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00691">691</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a9ecd21746d195133629292a6c85d5f3f"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">mic::types::MatrixPtr&lt;eT&gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::getParam </td>
          <td>(</td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>name_</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Returns the pointer to a parameter (matrix) (or throws an exception!) </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00277">277</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a03586b6b1863bb3f88cdb1aecf630bd3"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">mic::types::MatrixPtr&lt;eT&gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::getState </td>
          <td>(</td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>name_</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Returns the pointer to state (matrix) (or throws an exception!) </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00284">284</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="aeec074547484acb4de4124501fb10a58"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::inputSize </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns size (length) of inputs. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00255">255</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00091_source.html#l00082">mic::mlnn::convolution::MaxPooling&lt; eT &gt;::forward()</a>, <a class="el" href="a00098_source.html#l00131">mic::mlnn::fully_connected::HebbianLinear&lt; eT &gt;::getActivations()</a>, <a class="el" href="a00097_source.html#l00154">mic::mlnn::fully_connected::BinaryCorrelator&lt; eT &gt;::getActivations()</a>, <a class="el" href="a00101_source.html#l00183">mic::neural_nets::unit_tests::Linear50x100Double::Linear50x100Double()</a>, <a class="el" href="a00101_source.html#l00190">mic::neural_nets::unit_tests::Linear50x100Double::SetUp()</a>, <a class="el" href="a00086_source.html#l00165">mic::mlnn::convolution::Convolution&lt; float &gt;::streamLayerParameters()</a>, and <a class="el" href="a00104_source.html#l00363">mic::mlnn::Layer&lt; float &gt;::streamLayerParameters()</a>.</p>

</div>
</div>
<a class="anchor" id="a3ae69529f23d218b9fcad614e38d33e4"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::lazyAllocateMatrixVector </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; std::shared_ptr&lt; mic::types::Matrix&lt; eT &gt; &gt; &gt; &amp;&#160;</td>
          <td class="paramname"><em>vector_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>vector_size_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>matrix_height_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>matrix_width_</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Allocates memory to a matrix vector (lazy). </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">vector_</td><td>Vector that will store the matrices. </td></tr>
    <tr><td class="paramname">vector_size</td><td>Number of matrices to be added. </td></tr>
    <tr><td class="paramname">matrix_height_</td><td>Height of matrices. </td></tr>
    <tr><td class="paramname">matrix_width_</td><td>Width of matrices. </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="a00104_source.html#l00543">543</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00104_source.html#l00586">mic::mlnn::Layer&lt; float &gt;::getInputActivations()</a>, <a class="el" href="a00104_source.html#l00621">mic::mlnn::Layer&lt; float &gt;::getInputGradientActivations()</a>, <a class="el" href="a00099_source.html#l00249">mic::mlnn::fully_connected::Linear&lt; float &gt;::getInverseOutputActivations()</a>, <a class="el" href="a00086_source.html#l00707">mic::mlnn::convolution::Convolution&lt; float &gt;::getInverseReceptiveFields()</a>, <a class="el" href="a00099_source.html#l00219">mic::mlnn::fully_connected::Linear&lt; float &gt;::getInverseWeightActivations()</a>, <a class="el" href="a00096_source.html#l00132">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::getOutputActivations()</a>, <a class="el" href="a00104_source.html#l00656">mic::mlnn::Layer&lt; float &gt;::getOutputActivations()</a>, <a class="el" href="a00104_source.html#l00691">mic::mlnn::Layer&lt; float &gt;::getOutputGradientActivations()</a>, <a class="el" href="a00096_source.html#l00157">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::getOutputReconstruction()</a>, <a class="el" href="a00086_source.html#l00675">mic::mlnn::convolution::Convolution&lt; float &gt;::getReceptiveFields()</a>, <a class="el" href="a00099_source.html#l00173">mic::mlnn::fully_connected::Linear&lt; float &gt;::getWeightActivations()</a>, <a class="el" href="a00096_source.html#l00218">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::getWeightActivations()</a>, <a class="el" href="a00086_source.html#l00613">mic::mlnn::convolution::Convolution&lt; float &gt;::getWeightActivations()</a>, <a class="el" href="a00096_source.html#l00281">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::getWeightDissimilarity()</a>, <a class="el" href="a00099_source.html#l00196">mic::mlnn::fully_connected::Linear&lt; float &gt;::getWeightGradientActivations()</a>, <a class="el" href="a00086_source.html#l00644">mic::mlnn::convolution::Convolution&lt; float &gt;::getWeightGradientActivations()</a>, and <a class="el" href="a00096_source.html#l00244">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::getWeightSimilarity()</a>.</p>

</div>
</div>
<a class="anchor" id="a209b8398e28c682e63c895e2cac56507"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">mic::types::MatrixPtr&lt;eT&gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::lazyReturnChannelFromSample </td>
          <td>(</td>
          <td class="paramtype">mic::types::MatrixPtr&lt; eT &gt;&#160;</td>
          <td class="paramname"><em>sample_ptr_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">mic::types::MatrixArray&lt; eT &gt; &amp;&#160;</td>
          <td class="paramname"><em>array_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>id_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>sample_number_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>channel_number_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>height_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>width_</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Returns channel from a sample. If a given memory array does not contain such a memory pointer - it (lazy) allocates it. Assumes that: a) a sample is a column vector and b) there is one "channel memory ptr" for each sample (so the whole batch can be processed in parallel). OMP secured - critical section inside. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">sample_ptr</td><td>Pointer to a sample. </td></tr>
    <tr><td class="paramname">array_</td><td>Array of matrices where a given matrix (channel) is/will be stored. </td></tr>
    <tr><td class="paramname">id_</td><td>Channel id (variable prefix). </td></tr>
    <tr><td class="paramname">sample_number_</td><td>Number of the sample in batch. </td></tr>
    <tr><td class="paramname">channel_number_</td><td>Number of the channel. </td></tr>
    <tr><td class="paramname">height_</td><td>Height of the channel. </td></tr>
    <tr><td class="paramname">width_</td><td>Width of the channel. </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="a00104_source.html#l00487">487</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00104_source.html#l00519">mic::mlnn::Layer&lt; float &gt;::lazyReturnInputChannel()</a>, and <a class="el" href="a00104_source.html#l00530">mic::mlnn::Layer&lt; float &gt;::lazyReturnOutputChannel()</a>.</p>

</div>
</div>
<a class="anchor" id="a9ca3c12d05180ea01c604e0194f7b96f"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">mic::types::MatrixPtr&lt;eT&gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::lazyReturnInputChannel </td>
          <td>(</td>
          <td class="paramtype">mic::types::MatrixPtr&lt; eT &gt;&#160;</td>
          <td class="paramname"><em>sample_ptr_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>sample_number_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>channel_number_</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Returns input channel, with lazy matrix ptr allocation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">batch_ptr_</td><td>Pointer to a batch. </td></tr>
    <tr><td class="paramname">sample_number_</td><td>Number of the sample in batch. </td></tr>
    <tr><td class="paramname">channel_number_</td><td>Number of the channel in sample. </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="a00104_source.html#l00519">519</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00091_source.html#l00082">mic::mlnn::convolution::MaxPooling&lt; eT &gt;::forward()</a>.</p>

</div>
</div>
<a class="anchor" id="a76225cc40fc1aa81607fea6430e398b2"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">mic::types::MatrixPtr&lt;eT&gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::lazyReturnInputSample </td>
          <td>(</td>
          <td class="paramtype">mic::types::MatrixPtr&lt; eT &gt;&#160;</td>
          <td class="paramname"><em>batch_ptr_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>sample_number_</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Returns input sample, with lazy matrix ptr allocation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">batch_ptr_</td><td>Pointer to a batch. </td></tr>
    <tr><td class="paramname">sample_number_</td><td>Number of the sample in batch. </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="a00104_source.html#l00460">460</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00091_source.html#l00082">mic::mlnn::convolution::MaxPooling&lt; eT &gt;::forward()</a>.</p>

</div>
</div>
<a class="anchor" id="ad09e0efe88899effc76308dc526b6074"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">mic::types::MatrixPtr&lt;eT&gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::lazyReturnOutputChannel </td>
          <td>(</td>
          <td class="paramtype">mic::types::MatrixPtr&lt; eT &gt;&#160;</td>
          <td class="paramname"><em>sample_ptr_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>sample_number_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>channel_number_</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Returns output sample, with lazy matrix ptr allocation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">batch_ptr_</td><td>Pointer to a batch. </td></tr>
    <tr><td class="paramname">sample_number_</td><td>Number of the sample in batch. </td></tr>
    <tr><td class="paramname">channel_number_</td><td>Number of the channel in sample. </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="a00104_source.html#l00530">530</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="add6a26e84e77d387b8fcdadd9f7c85cf"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">mic::types::MatrixPtr&lt;eT&gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::lazyReturnOutputSample </td>
          <td>(</td>
          <td class="paramtype">mic::types::MatrixPtr&lt; eT &gt;&#160;</td>
          <td class="paramname"><em>batch_ptr_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>sample_number_</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Returns output sample, with lazy matrix ptr allocation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">batch_ptr_</td><td>Pointer to a batch. </td></tr>
    <tr><td class="paramname">sample_number_</td><td>Number of the sample in batch. </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="a00104_source.html#l00470">470</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a18a50dcf6752cd55b80f7a6f1a9defff"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">mic::types::MatrixPtr&lt;eT&gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::lazyReturnSampleFromBatch </td>
          <td>(</td>
          <td class="paramtype">mic::types::MatrixPtr&lt; eT &gt;&#160;</td>
          <td class="paramname"><em>batch_ptr_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">mic::types::MatrixArray&lt; eT &gt; &amp;&#160;</td>
          <td class="paramname"><em>array_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>id_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>sample_number_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>sample_size_</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Returns sample from batch. If a given memory array does not contain such a memory pointer - it (lazy) allocates it. OMP secured - critical section inside. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">batch_ptr_</td><td>Pointer to a batch. </td></tr>
    <tr><td class="paramname">array_</td><td>Array of matrices where a given matrix (sample) is/will be stored. </td></tr>
    <tr><td class="paramname">id_</td><td>Sample id (variable prefix). </td></tr>
    <tr><td class="paramname">sample_number_</td><td>Number of the sample in batch. </td></tr>
    <tr><td class="paramname">sample_size_</td><td>Size of the sample. </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="a00104_source.html#l00433">433</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00104_source.html#l00460">mic::mlnn::Layer&lt; float &gt;::lazyReturnInputSample()</a>, and <a class="el" href="a00104_source.html#l00470">mic::mlnn::Layer&lt; float &gt;::lazyReturnOutputSample()</a>.</p>

</div>
</div>
<a class="anchor" id="ac39c21ffbcc21efd0282e67c28f95c30"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const std::string <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::name </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns name of the layer. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00270">270</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a2c932ed1758edd3daf527bf99518e19c"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::outputSize </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns size (length) of outputs. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00260">260</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00102_source.html#l00075">mic::mlnn::fully_connected::SparseLinear&lt; eT &gt;::backward()</a>, <a class="el" href="a00091_source.html#l00082">mic::mlnn::convolution::MaxPooling&lt; eT &gt;::forward()</a>, <a class="el" href="a00098_source.html#l00131">mic::mlnn::fully_connected::HebbianLinear&lt; eT &gt;::getActivations()</a>, <a class="el" href="a00097_source.html#l00154">mic::mlnn::fully_connected::BinaryCorrelator&lt; eT &gt;::getActivations()</a>, <a class="el" href="a00101_source.html#l00183">mic::neural_nets::unit_tests::Linear50x100Double::Linear50x100Double()</a>, <a class="el" href="a00101_source.html#l00190">mic::neural_nets::unit_tests::Linear50x100Double::SetUp()</a>, <a class="el" href="a00102_source.html#l00049">mic::mlnn::fully_connected::SparseLinear&lt; eT &gt;::SparseLinear()</a>, <a class="el" href="a00086_source.html#l00165">mic::mlnn::convolution::Convolution&lt; float &gt;::streamLayerParameters()</a>, and <a class="el" href="a00104_source.html#l00363">mic::mlnn::Layer&lt; float &gt;::streamLayerParameters()</a>.</p>

</div>
</div>
<a class="anchor" id="a65896623f0fd96cbc00fc1ac4cf5ed4d"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::resetGrads </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Reset gradients. Virtual empty method - to be implemented by the inherited classes. </p>

<p>Reimplemented in <a class="el" href="a00022.html#a129da1330b1b8d7ce504b9237aed8330">mic::mlnn::convolution::Convolution&lt; eT &gt;</a>, <a class="el" href="a00022.html#a129da1330b1b8d7ce504b9237aed8330">mic::mlnn::convolution::Convolution&lt; double &gt;</a>, <a class="el" href="a00022.html#a129da1330b1b8d7ce504b9237aed8330">mic::mlnn::convolution::Convolution&lt; float &gt;</a>, <a class="el" href="a00034.html#a07591feef3af50098166fe870b594ed8">mic::mlnn::fully_connected::Linear&lt; eT &gt;</a>, <a class="el" href="a00034.html#a07591feef3af50098166fe870b594ed8">mic::mlnn::fully_connected::Linear&lt; double &gt;</a>, and <a class="el" href="a00034.html#a07591feef3af50098166fe870b594ed8">mic::mlnn::fully_connected::Linear&lt; float &gt;</a>.</p>

<p>Definition at line <a class="el" href="a00104_source.html#l00245">245</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a0e8c95b39579783dd698f2bd104bd2ac"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::resizeBatch </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>batch_size_</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Changes the size of the batch. By default it resizes state (x,y) and gradients (x,y). </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">New</td><td>size of the batch. </td></tr>
  </table>
  </dd>
</dl>

<p>Reimplemented in <a class="el" href="a00058.html#a105562e4b53f02fc4267aa75fcb6a3d4">mic::mlnn::cost_function::Softmax&lt; eT &gt;</a>, <a class="el" href="a00058.html#a105562e4b53f02fc4267aa75fcb6a3d4">mic::mlnn::cost_function::Softmax&lt; float &gt;</a>, <a class="el" href="a00042.html#a09e57d5d382428d0e2b43286344e79b2">mic::mlnn::convolution::MaxPooling&lt; eT &gt;</a>, and <a class="el" href="a00026.html#ab9d40bcc6c950d82eb773593a59049c6">mic::mlnn::regularisation::Dropout&lt; eT &gt;</a>.</p>

<p>Definition at line <a class="el" href="a00104_source.html#l00199">199</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00109_source.html#l00062">mic::mlnn::regularisation::Dropout&lt; eT &gt;::resizeBatch()</a>, <a class="el" href="a00091_source.html#l00072">mic::mlnn::convolution::MaxPooling&lt; eT &gt;::resizeBatch()</a>, and <a class="el" href="a00093_source.html#l00082">mic::mlnn::cost_function::Softmax&lt; float &gt;::resizeBatch()</a>.</p>

</div>
</div>
<a class="anchor" id="ab8f6c594af8da63691e1a52ebe4f5abf"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<div class="memtemplate">
template&lt;class Archive &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::serialize </td>
          <td>(</td>
          <td class="paramtype">Archive &amp;&#160;</td>
          <td class="paramname"><em>ar</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const unsigned int&#160;</td>
          <td class="paramname"><em>version</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Serializes the layer to and from archive. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ar</td><td>Used archive. </td></tr>
    <tr><td class="paramname">version</td><td>Version of the layer class (not used currently). </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="a00104_source.html#l00800">800</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="ae092b4068aee4967556bcba9ff4b81fe"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<div class="memtemplate">
template&lt;typename omT &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::setOptimization </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Sets the optimization method. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">omT</td><td>Optimization method type </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="a00104_source.html#l00307">307</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="aaa9f2ac12b09f7cb90ccc4587cd9ea10"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::setState </td>
          <td>(</td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>name_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">mic::types::MatrixPtr&lt; eT &gt;&#160;</td>
          <td class="paramname"><em>mat_ptr_</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Sets state (matrix) (or throws an exception!) </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00298">298</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a5d8d9bd174b1c243426eff80c6138f26"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual std::string <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::streamLayerParameters </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Stream layer parameters. </p>
<dl class="section return"><dt>Returns</dt><dd>Ostream object. </dd></dl>

<p>Reimplemented in <a class="el" href="a00022.html#ab847498b9dd666ac01158db23eb948bc">mic::mlnn::convolution::Convolution&lt; eT &gt;</a>, <a class="el" href="a00022.html#ab847498b9dd666ac01158db23eb948bc">mic::mlnn::convolution::Convolution&lt; double &gt;</a>, and <a class="el" href="a00022.html#ab847498b9dd666ac01158db23eb948bc">mic::mlnn::convolution::Convolution&lt; float &gt;</a>.</p>

<p>Definition at line <a class="el" href="a00104_source.html#l00363">363</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a596aeefd90b3bead3f6db8fdeb1ef1ce"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const std::string <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::type </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Returns the type of layer. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00323">323</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00086_source.html#l00165">mic::mlnn::convolution::Convolution&lt; float &gt;::streamLayerParameters()</a>, and <a class="el" href="a00104_source.html#l00363">mic::mlnn::Layer&lt; float &gt;::streamLayerParameters()</a>.</p>

</div>
</div>
<a class="anchor" id="afb1d1f61c2472d6cc3fce774df0b13c5"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::update </td>
          <td>(</td>
          <td class="paramtype">eT&#160;</td>
          <td class="paramname"><em>alpha_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">eT&#160;</td>
          <td class="paramname"><em>decay_</em> = <code>0.0f</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Performs the update according to the calculated gradients and injected optimization method. Abstract. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">alpha_</td><td>Learning rate - passed to the optimization functions of all layers. </td></tr>
    <tr><td class="paramname">decay_</td><td>Weight decay rate (determining that the "unused/unupdated" weights will decay to 0) (DEFAULT=0.0 - no decay). </td></tr>
  </table>
  </dd>
</dl>

<p>Implemented in <a class="el" href="a00022.html#adf3fdb1ae9e1bf1e46ee7e8db147f189">mic::mlnn::convolution::Convolution&lt; eT &gt;</a>, <a class="el" href="a00022.html#adf3fdb1ae9e1bf1e46ee7e8db147f189">mic::mlnn::convolution::Convolution&lt; double &gt;</a>, <a class="el" href="a00022.html#adf3fdb1ae9e1bf1e46ee7e8db147f189">mic::mlnn::convolution::Convolution&lt; float &gt;</a>, <a class="el" href="a00042.html#a590598663ad3bfa61ad277e694721740">mic::mlnn::convolution::MaxPooling&lt; eT &gt;</a>, <a class="el" href="a00034.html#a3ad6ca16dc6e41412cd3f02886c4a111">mic::mlnn::fully_connected::Linear&lt; eT &gt;</a>, <a class="el" href="a00034.html#a3ad6ca16dc6e41412cd3f02886c4a111">mic::mlnn::fully_connected::Linear&lt; double &gt;</a>, <a class="el" href="a00034.html#a3ad6ca16dc6e41412cd3f02886c4a111">mic::mlnn::fully_connected::Linear&lt; float &gt;</a>, <a class="el" href="a00023.html#a8490ab09b0da36d6dce45795e97df1a1">mic::mlnn::convolution::Cropping&lt; eT &gt;</a>, <a class="el" href="a00051.html#abd4ebfcba4faacb76ecf1e494f632828">mic::mlnn::convolution::Padding&lt; eT &gt;</a>, <a class="el" href="a00058.html#af5067a47d241c3cecf3c43f6789ef64b">mic::mlnn::cost_function::Softmax&lt; eT &gt;</a>, <a class="el" href="a00058.html#af5067a47d241c3cecf3c43f6789ef64b">mic::mlnn::cost_function::Softmax&lt; float &gt;</a>, <a class="el" href="a00009.html#a1b26fdb8f928f35febc0b00ff57183c6">mic::mlnn::fully_connected::BinaryCorrelator&lt; eT &gt;</a>, <a class="el" href="a00030.html#a664287e8db9f218df3c54df27267765d">mic::mlnn::fully_connected::HebbianLinear&lt; eT &gt;</a>, <a class="el" href="a00021.html#af9c6b99c497e46f8b901528520110689">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;</a>, <a class="el" href="a00026.html#ac6691315b1154dada99aafba3236b530">mic::mlnn::regularisation::Dropout&lt; eT &gt;</a>, <a class="el" href="a00052.html#a500c0128fe09b7e9e025dc5222c08e20">mic::mlnn::activation_function::ReLU&lt; eT &gt;</a>, <a class="el" href="a00027.html#abade4fbdd0ea2a0bc4ecba1c7ce6a2e9">mic::mlnn::activation_function::ELU&lt; eT &gt;</a>, <a class="el" href="a00056.html#ad5cd3871c485fd0301cd68bccfcd47b8">mic::mlnn::activation_function::Sigmoid&lt; eT &gt;</a>, and <a class="el" href="a00060.html#acf8073b9744fb6aa7759d9a5e59e3f80">mic::mlnn::fully_connected::SparseLinear&lt; eT &gt;</a>.</p>

</div>
</div>
<h2 class="groupheader">Friends And Related Function Documentation</h2>
<a class="anchor" id="aa365e3ee8444539572b26ddf4555c688"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<div class="memtemplate">
template&lt;typename tmp &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">friend class <a class="el" href="a00006.html">BackpropagationNeuralNetwork</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">friend</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Definition at line <a class="el" href="a00104_source.html#l00788">788</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="ac98d07dd8f7b70e16ccb9a01abf56b9c"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">friend class boost::serialization::access</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">friend</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Definition at line <a class="el" href="a00104_source.html#l00792">792</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a7d5de6e8e333572b800e9bf5822ed565"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<div class="memtemplate">
template&lt;typename tmp &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">friend class <a class="el" href="a00031.html">HebbianNeuralNetwork</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">friend</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Definition at line <a class="el" href="a00104_source.html#l00789">789</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="aa969764c5ebc6981d59d283733539c8b"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<div class="memtemplate">
template&lt;typename tmp &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">friend class <a class="el" href="a00046.html">MultiLayerNeuralNetwork</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">friend</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Definition at line <a class="el" href="a00104_source.html#l00787">787</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a5305245ebe24302b2a87eac1fd8792d6"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::ostream&amp; operator&lt;&lt; </td>
          <td>(</td>
          <td class="paramtype">std::ostream &amp;&#160;</td>
          <td class="paramname"><em>os_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="a00033.html">Layer</a>&lt; eT &gt; &amp;&#160;</td>
          <td class="paramname"><em>obj_</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">friend</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Stream operator enabling to print neural network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">os_</td><td>Ostream object. </td></tr>
    <tr><td class="paramname">obj_</td><td>Tensor object. </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="a00104_source.html#l00385">385</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a class="anchor" id="af8f8cecebc159b6bbecab3dd1a962652"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::batch_size</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Size (length) of (mini)batch. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00744">744</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00086_source.html#l00558">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_db()</a>, <a class="el" href="a00086_source.html#l00449">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dW()</a>, <a class="el" href="a00086_source.html#l00335">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dx()</a>, <a class="el" href="a00102_source.html#l00075">mic::mlnn::fully_connected::SparseLinear&lt; eT &gt;::backward()</a>, <a class="el" href="a00090_source.html#l00111">mic::mlnn::convolution::Cropping&lt; eT &gt;::backward()</a>, <a class="el" href="a00092_source.html#l00114">mic::mlnn::convolution::Padding&lt; eT &gt;::backward()</a>, <a class="el" href="a00104_source.html#l00265">mic::mlnn::Layer&lt; float &gt;::batchSize()</a>, <a class="el" href="a00099_source.html#l00289">mic::mlnn::fully_connected::Linear&lt; float &gt;::calculateMeanReconstructionError()</a>, <a class="el" href="a00086_source.html#l00054">mic::mlnn::convolution::Convolution&lt; float &gt;::Convolution()</a>, <a class="el" href="a00092_source.html#l00068">mic::mlnn::convolution::Padding&lt; eT &gt;::forward()</a>, <a class="el" href="a00090_source.html#l00068">mic::mlnn::convolution::Cropping&lt; eT &gt;::forward()</a>, <a class="el" href="a00091_source.html#l00082">mic::mlnn::convolution::MaxPooling&lt; eT &gt;::forward()</a>, <a class="el" href="a00086_source.html#l00186">mic::mlnn::convolution::Convolution&lt; float &gt;::forward()</a>, <a class="el" href="a00104_source.html#l00586">mic::mlnn::Layer&lt; float &gt;::getInputActivations()</a>, <a class="el" href="a00104_source.html#l00621">mic::mlnn::Layer&lt; float &gt;::getInputGradientActivations()</a>, <a class="el" href="a00099_source.html#l00249">mic::mlnn::fully_connected::Linear&lt; float &gt;::getInverseOutputActivations()</a>, <a class="el" href="a00104_source.html#l00656">mic::mlnn::Layer&lt; float &gt;::getOutputActivations()</a>, <a class="el" href="a00104_source.html#l00691">mic::mlnn::Layer&lt; float &gt;::getOutputGradientActivations()</a>, <a class="el" href="a00104_source.html#l00107">mic::mlnn::Layer&lt; float &gt;::Layer()</a>, <a class="el" href="a00104_source.html#l00199">mic::mlnn::Layer&lt; float &gt;::resizeBatch()</a>, <a class="el" href="a00104_source.html#l00800">mic::mlnn::Layer&lt; float &gt;::serialize()</a>, <a class="el" href="a00086_source.html#l00165">mic::mlnn::convolution::Convolution&lt; float &gt;::streamLayerParameters()</a>, and <a class="el" href="a00104_source.html#l00363">mic::mlnn::Layer&lt; float &gt;::streamLayerParameters()</a>.</p>

</div>
</div>
<a class="anchor" id="a953514d3d0a642bdb64df6d79f33d277"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; std::shared_ptr &lt;mic::types::Matrix&lt;eT&gt; &gt; &gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::dx_activations</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Vector containing activations of gradients of inputs (dx) - used in visualization. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00771">771</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00104_source.html#l00621">mic::mlnn::Layer&lt; float &gt;::getInputGradientActivations()</a>.</p>

</div>
</div>
<a class="anchor" id="a8033474a7f1821f682e0ee347b8ad221"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; std::shared_ptr &lt;mic::types::Matrix&lt;eT&gt; &gt; &gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::dy_activations</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Vector containing activations of gradients of outputs (dy) - used in visualization. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00777">777</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00104_source.html#l00691">mic::mlnn::Layer&lt; float &gt;::getOutputGradientActivations()</a>.</p>

</div>
</div>
<a class="anchor" id="aca32d9cfff631e2c529f469647a90570"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">mic::types::MatrixArray&lt;eT&gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::g</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gradients - contains input [x] and output [y] matrices. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00756">756</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00086_source.html#l00558">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_db()</a>, <a class="el" href="a00086_source.html#l00449">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dW()</a>, <a class="el" href="a00086_source.html#l00335">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dx()</a>, <a class="el" href="a00102_source.html#l00075">mic::mlnn::fully_connected::SparseLinear&lt; eT &gt;::backward()</a>, <a class="el" href="a00084_source.html#l00082">mic::mlnn::activation_function::Sigmoid&lt; eT &gt;::backward()</a>, <a class="el" href="a00082_source.html#l00086">mic::mlnn::activation_function::ELU&lt; eT &gt;::backward()</a>, <a class="el" href="a00083_source.html#l00087">mic::mlnn::activation_function::ReLU&lt; eT &gt;::backward()</a>, <a class="el" href="a00109_source.html#l00101">mic::mlnn::regularisation::Dropout&lt; eT &gt;::backward()</a>, <a class="el" href="a00090_source.html#l00111">mic::mlnn::convolution::Cropping&lt; eT &gt;::backward()</a>, <a class="el" href="a00092_source.html#l00114">mic::mlnn::convolution::Padding&lt; eT &gt;::backward()</a>, <a class="el" href="a00093_source.html#l00124">mic::mlnn::cost_function::Softmax&lt; float &gt;::backward()</a>, <a class="el" href="a00099_source.html#l00126">mic::mlnn::fully_connected::Linear&lt; float &gt;::backward()</a>, <a class="el" href="a00091_source.html#l00152">mic::mlnn::convolution::MaxPooling&lt; eT &gt;::backward()</a>, <a class="el" href="a00104_source.html#l00184">mic::mlnn::Layer&lt; float &gt;::backward()</a>, <a class="el" href="a00086_source.html#l00296">mic::mlnn::convolution::Convolution&lt; float &gt;::backward()</a>, <a class="el" href="a00086_source.html#l00054">mic::mlnn::convolution::Convolution&lt; float &gt;::Convolution()</a>, <a class="el" href="a00104_source.html#l00291">mic::mlnn::Layer&lt; float &gt;::getGradient()</a>, <a class="el" href="a00104_source.html#l00621">mic::mlnn::Layer&lt; float &gt;::getInputGradientActivations()</a>, <a class="el" href="a00104_source.html#l00691">mic::mlnn::Layer&lt; float &gt;::getOutputGradientActivations()</a>, <a class="el" href="a00099_source.html#l00196">mic::mlnn::fully_connected::Linear&lt; float &gt;::getWeightGradientActivations()</a>, <a class="el" href="a00086_source.html#l00644">mic::mlnn::convolution::Convolution&lt; float &gt;::getWeightGradientActivations()</a>, <a class="el" href="a00104_source.html#l00107">mic::mlnn::Layer&lt; float &gt;::Layer()</a>, <a class="el" href="a00099_source.html#l00148">mic::mlnn::fully_connected::Linear&lt; float &gt;::resetGrads()</a>, <a class="el" href="a00086_source.html#l00579">mic::mlnn::convolution::Convolution&lt; float &gt;::resetGrads()</a>, <a class="el" href="a00104_source.html#l00199">mic::mlnn::Layer&lt; float &gt;::resizeBatch()</a>, <a class="el" href="a00104_source.html#l00800">mic::mlnn::Layer&lt; float &gt;::serialize()</a>, <a class="el" href="a00101_source.html#l00090">mic::neural_nets::unit_tests::Linear2x3Float::SetUp()</a>, <a class="el" href="a00101_source.html#l00141">mic::neural_nets::unit_tests::Linear2x3Double::SetUp()</a>, <a class="el" href="a00101_source.html#l00190">mic::neural_nets::unit_tests::Linear50x100Double::SetUp()</a>, <a class="el" href="a00102_source.html#l00098">mic::mlnn::fully_connected::SparseLinear&lt; eT &gt;::update()</a>, <a class="el" href="a00099_source.html#l00159">mic::mlnn::fully_connected::Linear&lt; float &gt;::update()</a>, and <a class="el" href="a00086_source.html#l00590">mic::mlnn::convolution::Convolution&lt; float &gt;::update()</a>.</p>

</div>
</div>
<a class="anchor" id="a051e607097e1b8491ceab635a1105ff6"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::input_depth</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Number of channels of the input (e.g. 3 for RGB images). </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00732">732</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00086_source.html#l00449">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dW()</a>, <a class="el" href="a00086_source.html#l00335">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dx()</a>, <a class="el" href="a00090_source.html#l00111">mic::mlnn::convolution::Cropping&lt; eT &gt;::backward()</a>, <a class="el" href="a00092_source.html#l00114">mic::mlnn::convolution::Padding&lt; eT &gt;::backward()</a>, <a class="el" href="a00099_source.html#l00289">mic::mlnn::fully_connected::Linear&lt; float &gt;::calculateMeanReconstructionError()</a>, <a class="el" href="a00086_source.html#l00054">mic::mlnn::convolution::Convolution&lt; float &gt;::Convolution()</a>, <a class="el" href="a00090_source.html#l00068">mic::mlnn::convolution::Cropping&lt; eT &gt;::forward()</a>, <a class="el" href="a00092_source.html#l00068">mic::mlnn::convolution::Padding&lt; eT &gt;::forward()</a>, <a class="el" href="a00091_source.html#l00082">mic::mlnn::convolution::MaxPooling&lt; eT &gt;::forward()</a>, <a class="el" href="a00086_source.html#l00186">mic::mlnn::convolution::Convolution&lt; float &gt;::forward()</a>, <a class="el" href="a00086_source.html#l00738">mic::mlnn::convolution::Convolution&lt; float &gt;::getFilterSimilarityMatrix()</a>, <a class="el" href="a00104_source.html#l00586">mic::mlnn::Layer&lt; float &gt;::getInputActivations()</a>, <a class="el" href="a00104_source.html#l00621">mic::mlnn::Layer&lt; float &gt;::getInputGradientActivations()</a>, <a class="el" href="a00099_source.html#l00249">mic::mlnn::fully_connected::Linear&lt; float &gt;::getInverseOutputActivations()</a>, <a class="el" href="a00099_source.html#l00219">mic::mlnn::fully_connected::Linear&lt; float &gt;::getInverseWeightActivations()</a>, <a class="el" href="a00086_source.html#l00613">mic::mlnn::convolution::Convolution&lt; float &gt;::getWeightActivations()</a>, <a class="el" href="a00086_source.html#l00644">mic::mlnn::convolution::Convolution&lt; float &gt;::getWeightGradientActivations()</a>, <a class="el" href="a00104_source.html#l00255">mic::mlnn::Layer&lt; float &gt;::inputSize()</a>, <a class="el" href="a00104_source.html#l00107">mic::mlnn::Layer&lt; float &gt;::Layer()</a>, <a class="el" href="a00104_source.html#l00800">mic::mlnn::Layer&lt; float &gt;::serialize()</a>, <a class="el" href="a00086_source.html#l00165">mic::mlnn::convolution::Convolution&lt; float &gt;::streamLayerParameters()</a>, and <a class="el" href="a00104_source.html#l00363">mic::mlnn::Layer&lt; float &gt;::streamLayerParameters()</a>.</p>

</div>
</div>
<a class="anchor" id="a30ee8b10b8c7425e6c987359b7bbf8fc"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::input_height</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Height of the input (e.g. 28 for MNIST). </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00726">726</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00086_source.html#l00449">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dW()</a>, <a class="el" href="a00086_source.html#l00335">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dx()</a>, <a class="el" href="a00090_source.html#l00111">mic::mlnn::convolution::Cropping&lt; eT &gt;::backward()</a>, <a class="el" href="a00092_source.html#l00114">mic::mlnn::convolution::Padding&lt; eT &gt;::backward()</a>, <a class="el" href="a00099_source.html#l00289">mic::mlnn::fully_connected::Linear&lt; float &gt;::calculateMeanReconstructionError()</a>, <a class="el" href="a00086_source.html#l00054">mic::mlnn::convolution::Convolution&lt; float &gt;::Convolution()</a>, <a class="el" href="a00092_source.html#l00068">mic::mlnn::convolution::Padding&lt; eT &gt;::forward()</a>, <a class="el" href="a00090_source.html#l00068">mic::mlnn::convolution::Cropping&lt; eT &gt;::forward()</a>, <a class="el" href="a00091_source.html#l00082">mic::mlnn::convolution::MaxPooling&lt; eT &gt;::forward()</a>, <a class="el" href="a00086_source.html#l00186">mic::mlnn::convolution::Convolution&lt; float &gt;::forward()</a>, <a class="el" href="a00104_source.html#l00586">mic::mlnn::Layer&lt; float &gt;::getInputActivations()</a>, <a class="el" href="a00104_source.html#l00621">mic::mlnn::Layer&lt; float &gt;::getInputGradientActivations()</a>, <a class="el" href="a00099_source.html#l00249">mic::mlnn::fully_connected::Linear&lt; float &gt;::getInverseOutputActivations()</a>, <a class="el" href="a00099_source.html#l00219">mic::mlnn::fully_connected::Linear&lt; float &gt;::getInverseWeightActivations()</a>, <a class="el" href="a00096_source.html#l00157">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::getOutputReconstruction()</a>, <a class="el" href="a00104_source.html#l00255">mic::mlnn::Layer&lt; float &gt;::inputSize()</a>, <a class="el" href="a00104_source.html#l00107">mic::mlnn::Layer&lt; float &gt;::Layer()</a>, <a class="el" href="a00104_source.html#l00519">mic::mlnn::Layer&lt; float &gt;::lazyReturnInputChannel()</a>, <a class="el" href="a00104_source.html#l00800">mic::mlnn::Layer&lt; float &gt;::serialize()</a>, <a class="el" href="a00086_source.html#l00165">mic::mlnn::convolution::Convolution&lt; float &gt;::streamLayerParameters()</a>, and <a class="el" href="a00104_source.html#l00363">mic::mlnn::Layer&lt; float &gt;::streamLayerParameters()</a>.</p>

</div>
</div>
<a class="anchor" id="a9789ac1e5becaef7a112f069bd63a957"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::input_width</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Width of the input (e.g. 28 for MNIST). </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00729">729</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00086_source.html#l00449">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dW()</a>, <a class="el" href="a00086_source.html#l00335">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dx()</a>, <a class="el" href="a00090_source.html#l00111">mic::mlnn::convolution::Cropping&lt; eT &gt;::backward()</a>, <a class="el" href="a00092_source.html#l00114">mic::mlnn::convolution::Padding&lt; eT &gt;::backward()</a>, <a class="el" href="a00099_source.html#l00289">mic::mlnn::fully_connected::Linear&lt; float &gt;::calculateMeanReconstructionError()</a>, <a class="el" href="a00086_source.html#l00054">mic::mlnn::convolution::Convolution&lt; float &gt;::Convolution()</a>, <a class="el" href="a00092_source.html#l00068">mic::mlnn::convolution::Padding&lt; eT &gt;::forward()</a>, <a class="el" href="a00090_source.html#l00068">mic::mlnn::convolution::Cropping&lt; eT &gt;::forward()</a>, <a class="el" href="a00091_source.html#l00082">mic::mlnn::convolution::MaxPooling&lt; eT &gt;::forward()</a>, <a class="el" href="a00096_source.html#l00085">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::forward()</a>, <a class="el" href="a00086_source.html#l00186">mic::mlnn::convolution::Convolution&lt; float &gt;::forward()</a>, <a class="el" href="a00104_source.html#l00586">mic::mlnn::Layer&lt; float &gt;::getInputActivations()</a>, <a class="el" href="a00104_source.html#l00621">mic::mlnn::Layer&lt; float &gt;::getInputGradientActivations()</a>, <a class="el" href="a00099_source.html#l00249">mic::mlnn::fully_connected::Linear&lt; float &gt;::getInverseOutputActivations()</a>, <a class="el" href="a00099_source.html#l00219">mic::mlnn::fully_connected::Linear&lt; float &gt;::getInverseWeightActivations()</a>, <a class="el" href="a00096_source.html#l00157">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::getOutputReconstruction()</a>, <a class="el" href="a00104_source.html#l00255">mic::mlnn::Layer&lt; float &gt;::inputSize()</a>, <a class="el" href="a00104_source.html#l00107">mic::mlnn::Layer&lt; float &gt;::Layer()</a>, <a class="el" href="a00104_source.html#l00519">mic::mlnn::Layer&lt; float &gt;::lazyReturnInputChannel()</a>, <a class="el" href="a00104_source.html#l00800">mic::mlnn::Layer&lt; float &gt;::serialize()</a>, <a class="el" href="a00086_source.html#l00165">mic::mlnn::convolution::Convolution&lt; float &gt;::streamLayerParameters()</a>, and <a class="el" href="a00104_source.html#l00363">mic::mlnn::Layer&lt; float &gt;::streamLayerParameters()</a>.</p>

</div>
</div>
<a class="anchor" id="a289e418de1cf2e2582b99d9d9f19cc02"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::string <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::layer_name</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Name (identifier of the type) of the layer. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00750">750</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00104_source.html#l00270">mic::mlnn::Layer&lt; float &gt;::name()</a>, <a class="el" href="a00104_source.html#l00800">mic::mlnn::Layer&lt; float &gt;::serialize()</a>, and <a class="el" href="a00104_source.html#l00363">mic::mlnn::Layer&lt; float &gt;::streamLayerParameters()</a>.</p>

</div>
</div>
<a class="anchor" id="a6b5806d64072a7882f21ed7cf1ddffb2"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="a00153.html#a89105a145f4cf2ba1557d5e669a8a0f5">LayerTypes</a> <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::layer_type</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Type of the layer. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00747">747</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00104_source.html#l00800">mic::mlnn::Layer&lt; float &gt;::serialize()</a>, and <a class="el" href="a00104_source.html#l00323">mic::mlnn::Layer&lt; float &gt;::type()</a>.</p>

</div>
</div>
<a class="anchor" id="af591178808a0b219eb6c42666872db24"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">mic::types::MatrixArray&lt;eT&gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::m</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Memory - a list of temporal parameters, to be used by the derived classes. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00762">762</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00086_source.html#l00449">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dW()</a>, <a class="el" href="a00086_source.html#l00335">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dx()</a>, <a class="el" href="a00102_source.html#l00075">mic::mlnn::fully_connected::SparseLinear&lt; eT &gt;::backward()</a>, <a class="el" href="a00109_source.html#l00101">mic::mlnn::regularisation::Dropout&lt; eT &gt;::backward()</a>, <a class="el" href="a00091_source.html#l00152">mic::mlnn::convolution::MaxPooling&lt; eT &gt;::backward()</a>, <a class="el" href="a00097_source.html#l00066">mic::mlnn::fully_connected::BinaryCorrelator&lt; eT &gt;::BinaryCorrelator()</a>, <a class="el" href="a00099_source.html#l00289">mic::mlnn::fully_connected::Linear&lt; float &gt;::calculateMeanReconstructionError()</a>, <a class="el" href="a00104_source.html#l00219">mic::mlnn::Layer&lt; float &gt;::calculateNumericalGradient()</a>, <a class="el" href="a00086_source.html#l00054">mic::mlnn::convolution::Convolution&lt; float &gt;::Convolution()</a>, <a class="el" href="a00109_source.html#l00045">mic::mlnn::regularisation::Dropout&lt; eT &gt;::Dropout()</a>, <a class="el" href="a00109_source.html#l00071">mic::mlnn::regularisation::Dropout&lt; eT &gt;::forward()</a>, <a class="el" href="a00091_source.html#l00082">mic::mlnn::convolution::MaxPooling&lt; eT &gt;::forward()</a>, <a class="el" href="a00093_source.html#l00094">mic::mlnn::cost_function::Softmax&lt; float &gt;::forward()</a>, <a class="el" href="a00097_source.html#l00107">mic::mlnn::fully_connected::BinaryCorrelator&lt; eT &gt;::forward()</a>, <a class="el" href="a00086_source.html#l00186">mic::mlnn::convolution::Convolution&lt; float &gt;::forward()</a>, <a class="el" href="a00086_source.html#l00738">mic::mlnn::convolution::Convolution&lt; float &gt;::getFilterSimilarityMatrix()</a>, <a class="el" href="a00104_source.html#l00586">mic::mlnn::Layer&lt; float &gt;::getInputActivations()</a>, <a class="el" href="a00104_source.html#l00621">mic::mlnn::Layer&lt; float &gt;::getInputGradientActivations()</a>, <a class="el" href="a00099_source.html#l00249">mic::mlnn::fully_connected::Linear&lt; float &gt;::getInverseOutputActivations()</a>, <a class="el" href="a00086_source.html#l00707">mic::mlnn::convolution::Convolution&lt; float &gt;::getInverseReceptiveFields()</a>, <a class="el" href="a00104_source.html#l00656">mic::mlnn::Layer&lt; float &gt;::getOutputActivations()</a>, <a class="el" href="a00104_source.html#l00691">mic::mlnn::Layer&lt; float &gt;::getOutputGradientActivations()</a>, <a class="el" href="a00086_source.html#l00675">mic::mlnn::convolution::Convolution&lt; float &gt;::getReceptiveFields()</a>, <a class="el" href="a00104_source.html#l00107">mic::mlnn::Layer&lt; float &gt;::Layer()</a>, <a class="el" href="a00104_source.html#l00543">mic::mlnn::Layer&lt; float &gt;::lazyAllocateMatrixVector()</a>, <a class="el" href="a00104_source.html#l00487">mic::mlnn::Layer&lt; float &gt;::lazyReturnChannelFromSample()</a>, <a class="el" href="a00104_source.html#l00519">mic::mlnn::Layer&lt; float &gt;::lazyReturnInputChannel()</a>, <a class="el" href="a00104_source.html#l00460">mic::mlnn::Layer&lt; float &gt;::lazyReturnInputSample()</a>, <a class="el" href="a00104_source.html#l00530">mic::mlnn::Layer&lt; float &gt;::lazyReturnOutputChannel()</a>, <a class="el" href="a00104_source.html#l00470">mic::mlnn::Layer&lt; float &gt;::lazyReturnOutputSample()</a>, <a class="el" href="a00104_source.html#l00433">mic::mlnn::Layer&lt; float &gt;::lazyReturnSampleFromBatch()</a>, <a class="el" href="a00091_source.html#l00051">mic::mlnn::convolution::MaxPooling&lt; eT &gt;::MaxPooling()</a>, <a class="el" href="a00109_source.html#l00062">mic::mlnn::regularisation::Dropout&lt; eT &gt;::resizeBatch()</a>, <a class="el" href="a00091_source.html#l00072">mic::mlnn::convolution::MaxPooling&lt; eT &gt;::resizeBatch()</a>, <a class="el" href="a00093_source.html#l00082">mic::mlnn::cost_function::Softmax&lt; float &gt;::resizeBatch()</a>, <a class="el" href="a00104_source.html#l00800">mic::mlnn::Layer&lt; float &gt;::serialize()</a>, <a class="el" href="a00093_source.html#l00060">mic::mlnn::cost_function::Softmax&lt; float &gt;::Softmax()</a>, <a class="el" href="a00102_source.html#l00049">mic::mlnn::fully_connected::SparseLinear&lt; eT &gt;::SparseLinear()</a>, <a class="el" href="a00102_source.html#l00098">mic::mlnn::fully_connected::SparseLinear&lt; eT &gt;::update()</a>, and <a class="el" href="a00097_source.html#l00134">mic::mlnn::fully_connected::BinaryCorrelator&lt; eT &gt;::update()</a>.</p>

</div>
</div>
<a class="anchor" id="a75b903652bcbb62dfb22be34af7e0c8e"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="a00049.html">mic::neural_nets::optimization::OptimizationArray</a>&lt;eT&gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::opt</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Array of optimization functions. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00765">765</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00104_source.html#l00307">mic::mlnn::Layer&lt; float &gt;::setOptimization()</a>, <a class="el" href="a00102_source.html#l00098">mic::mlnn::fully_connected::SparseLinear&lt; eT &gt;::update()</a>, <a class="el" href="a00096_source.html#l00123">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::update()</a>, <a class="el" href="a00098_source.html#l00124">mic::mlnn::fully_connected::HebbianLinear&lt; eT &gt;::update()</a>, <a class="el" href="a00097_source.html#l00134">mic::mlnn::fully_connected::BinaryCorrelator&lt; eT &gt;::update()</a>, <a class="el" href="a00099_source.html#l00159">mic::mlnn::fully_connected::Linear&lt; float &gt;::update()</a>, and <a class="el" href="a00086_source.html#l00590">mic::mlnn::convolution::Convolution&lt; float &gt;::update()</a>.</p>

</div>
</div>
<a class="anchor" id="a42ae81a0beee2d26d67eee2333f24679"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::output_depth</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Number of filters = number of output channels. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00741">741</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00086_source.html#l00558">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_db()</a>, <a class="el" href="a00086_source.html#l00449">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dW()</a>, <a class="el" href="a00086_source.html#l00335">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dx()</a>, <a class="el" href="a00086_source.html#l00054">mic::mlnn::convolution::Convolution&lt; float &gt;::Convolution()</a>, <a class="el" href="a00086_source.html#l00186">mic::mlnn::convolution::Convolution&lt; float &gt;::forward()</a>, <a class="el" href="a00086_source.html#l00738">mic::mlnn::convolution::Convolution&lt; float &gt;::getFilterSimilarityMatrix()</a>, <a class="el" href="a00099_source.html#l00219">mic::mlnn::fully_connected::Linear&lt; float &gt;::getInverseWeightActivations()</a>, <a class="el" href="a00104_source.html#l00656">mic::mlnn::Layer&lt; float &gt;::getOutputActivations()</a>, <a class="el" href="a00104_source.html#l00691">mic::mlnn::Layer&lt; float &gt;::getOutputGradientActivations()</a>, <a class="el" href="a00086_source.html#l00613">mic::mlnn::convolution::Convolution&lt; float &gt;::getWeightActivations()</a>, <a class="el" href="a00086_source.html#l00644">mic::mlnn::convolution::Convolution&lt; float &gt;::getWeightGradientActivations()</a>, <a class="el" href="a00104_source.html#l00107">mic::mlnn::Layer&lt; float &gt;::Layer()</a>, <a class="el" href="a00104_source.html#l00260">mic::mlnn::Layer&lt; float &gt;::outputSize()</a>, <a class="el" href="a00104_source.html#l00800">mic::mlnn::Layer&lt; float &gt;::serialize()</a>, <a class="el" href="a00086_source.html#l00165">mic::mlnn::convolution::Convolution&lt; float &gt;::streamLayerParameters()</a>, and <a class="el" href="a00104_source.html#l00363">mic::mlnn::Layer&lt; float &gt;::streamLayerParameters()</a>.</p>

</div>
</div>
<a class="anchor" id="a97d292eb9f57fc8a55b824ca03dd2bf6"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::output_height</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Number of receptive fields in a single channel - vertical direction. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00735">735</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00086_source.html#l00558">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_db()</a>, <a class="el" href="a00086_source.html#l00449">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dW()</a>, <a class="el" href="a00086_source.html#l00335">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dx()</a>, <a class="el" href="a00090_source.html#l00111">mic::mlnn::convolution::Cropping&lt; eT &gt;::backward()</a>, <a class="el" href="a00086_source.html#l00054">mic::mlnn::convolution::Convolution&lt; float &gt;::Convolution()</a>, <a class="el" href="a00090_source.html#l00068">mic::mlnn::convolution::Cropping&lt; eT &gt;::forward()</a>, <a class="el" href="a00091_source.html#l00082">mic::mlnn::convolution::MaxPooling&lt; eT &gt;::forward()</a>, <a class="el" href="a00096_source.html#l00085">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::forward()</a>, <a class="el" href="a00086_source.html#l00186">mic::mlnn::convolution::Convolution&lt; float &gt;::forward()</a>, <a class="el" href="a00086_source.html#l00707">mic::mlnn::convolution::Convolution&lt; float &gt;::getInverseReceptiveFields()</a>, <a class="el" href="a00099_source.html#l00219">mic::mlnn::fully_connected::Linear&lt; float &gt;::getInverseWeightActivations()</a>, <a class="el" href="a00096_source.html#l00132">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::getOutputActivations()</a>, <a class="el" href="a00104_source.html#l00656">mic::mlnn::Layer&lt; float &gt;::getOutputActivations()</a>, <a class="el" href="a00104_source.html#l00691">mic::mlnn::Layer&lt; float &gt;::getOutputGradientActivations()</a>, <a class="el" href="a00096_source.html#l00157">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::getOutputReconstruction()</a>, <a class="el" href="a00086_source.html#l00675">mic::mlnn::convolution::Convolution&lt; float &gt;::getReceptiveFields()</a>, <a class="el" href="a00104_source.html#l00107">mic::mlnn::Layer&lt; float &gt;::Layer()</a>, <a class="el" href="a00104_source.html#l00530">mic::mlnn::Layer&lt; float &gt;::lazyReturnOutputChannel()</a>, <a class="el" href="a00104_source.html#l00260">mic::mlnn::Layer&lt; float &gt;::outputSize()</a>, <a class="el" href="a00104_source.html#l00800">mic::mlnn::Layer&lt; float &gt;::serialize()</a>, <a class="el" href="a00086_source.html#l00165">mic::mlnn::convolution::Convolution&lt; float &gt;::streamLayerParameters()</a>, <a class="el" href="a00104_source.html#l00363">mic::mlnn::Layer&lt; float &gt;::streamLayerParameters()</a>, and <a class="el" href="a00088_source.html#l00033">mic::neural_nets::unit_tests::TEST()</a>.</p>

</div>
</div>
<a class="anchor" id="af557b9cb28961ea3a6e0f8bd7159f108"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::output_width</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Number of receptive fields in a single channel - horizontal direction. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00738">738</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00086_source.html#l00558">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_db()</a>, <a class="el" href="a00086_source.html#l00449">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dW()</a>, <a class="el" href="a00086_source.html#l00335">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dx()</a>, <a class="el" href="a00090_source.html#l00111">mic::mlnn::convolution::Cropping&lt; eT &gt;::backward()</a>, <a class="el" href="a00086_source.html#l00054">mic::mlnn::convolution::Convolution&lt; float &gt;::Convolution()</a>, <a class="el" href="a00090_source.html#l00068">mic::mlnn::convolution::Cropping&lt; eT &gt;::forward()</a>, <a class="el" href="a00091_source.html#l00082">mic::mlnn::convolution::MaxPooling&lt; eT &gt;::forward()</a>, <a class="el" href="a00096_source.html#l00085">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::forward()</a>, <a class="el" href="a00086_source.html#l00186">mic::mlnn::convolution::Convolution&lt; float &gt;::forward()</a>, <a class="el" href="a00086_source.html#l00707">mic::mlnn::convolution::Convolution&lt; float &gt;::getInverseReceptiveFields()</a>, <a class="el" href="a00099_source.html#l00219">mic::mlnn::fully_connected::Linear&lt; float &gt;::getInverseWeightActivations()</a>, <a class="el" href="a00096_source.html#l00132">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::getOutputActivations()</a>, <a class="el" href="a00104_source.html#l00656">mic::mlnn::Layer&lt; float &gt;::getOutputActivations()</a>, <a class="el" href="a00104_source.html#l00691">mic::mlnn::Layer&lt; float &gt;::getOutputGradientActivations()</a>, <a class="el" href="a00096_source.html#l00157">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::getOutputReconstruction()</a>, <a class="el" href="a00086_source.html#l00675">mic::mlnn::convolution::Convolution&lt; float &gt;::getReceptiveFields()</a>, <a class="el" href="a00104_source.html#l00107">mic::mlnn::Layer&lt; float &gt;::Layer()</a>, <a class="el" href="a00104_source.html#l00530">mic::mlnn::Layer&lt; float &gt;::lazyReturnOutputChannel()</a>, <a class="el" href="a00104_source.html#l00260">mic::mlnn::Layer&lt; float &gt;::outputSize()</a>, <a class="el" href="a00104_source.html#l00800">mic::mlnn::Layer&lt; float &gt;::serialize()</a>, <a class="el" href="a00086_source.html#l00165">mic::mlnn::convolution::Convolution&lt; float &gt;::streamLayerParameters()</a>, <a class="el" href="a00104_source.html#l00363">mic::mlnn::Layer&lt; float &gt;::streamLayerParameters()</a>, and <a class="el" href="a00088_source.html#l00033">mic::neural_nets::unit_tests::TEST()</a>.</p>

</div>
</div>
<a class="anchor" id="ac06ea0597a86992a70429e4926504f01"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">mic::types::MatrixArray&lt;eT&gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::p</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Parameters - parameters of the layer, to be used by the derived classes. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00759">759</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00086_source.html#l00335">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dx()</a>, <a class="el" href="a00102_source.html#l00075">mic::mlnn::fully_connected::SparseLinear&lt; eT &gt;::backward()</a>, <a class="el" href="a00099_source.html#l00126">mic::mlnn::fully_connected::Linear&lt; float &gt;::backward()</a>, <a class="el" href="a00097_source.html#l00066">mic::mlnn::fully_connected::BinaryCorrelator&lt; eT &gt;::BinaryCorrelator()</a>, <a class="el" href="a00104_source.html#l00219">mic::mlnn::Layer&lt; float &gt;::calculateNumericalGradient()</a>, <a class="el" href="a00096_source.html#l00049">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::ConvHebbian()</a>, <a class="el" href="a00086_source.html#l00054">mic::mlnn::convolution::Convolution&lt; float &gt;::Convolution()</a>, <a class="el" href="a00096_source.html#l00085">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::forward()</a>, <a class="el" href="a00098_source.html#l00095">mic::mlnn::fully_connected::HebbianLinear&lt; eT &gt;::forward()</a>, <a class="el" href="a00099_source.html#l00105">mic::mlnn::fully_connected::Linear&lt; float &gt;::forward()</a>, <a class="el" href="a00086_source.html#l00186">mic::mlnn::convolution::Convolution&lt; float &gt;::forward()</a>, <a class="el" href="a00098_source.html#l00131">mic::mlnn::fully_connected::HebbianLinear&lt; eT &gt;::getActivations()</a>, <a class="el" href="a00097_source.html#l00154">mic::mlnn::fully_connected::BinaryCorrelator&lt; eT &gt;::getActivations()</a>, <a class="el" href="a00086_source.html#l00738">mic::mlnn::convolution::Convolution&lt; float &gt;::getFilterSimilarityMatrix()</a>, <a class="el" href="a00099_source.html#l00249">mic::mlnn::fully_connected::Linear&lt; float &gt;::getInverseOutputActivations()</a>, <a class="el" href="a00099_source.html#l00219">mic::mlnn::fully_connected::Linear&lt; float &gt;::getInverseWeightActivations()</a>, <a class="el" href="a00096_source.html#l00157">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::getOutputReconstruction()</a>, <a class="el" href="a00104_source.html#l00277">mic::mlnn::Layer&lt; float &gt;::getParam()</a>, <a class="el" href="a00099_source.html#l00173">mic::mlnn::fully_connected::Linear&lt; float &gt;::getWeightActivations()</a>, <a class="el" href="a00096_source.html#l00218">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::getWeightActivations()</a>, <a class="el" href="a00086_source.html#l00613">mic::mlnn::convolution::Convolution&lt; float &gt;::getWeightActivations()</a>, <a class="el" href="a00096_source.html#l00281">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::getWeightDissimilarity()</a>, <a class="el" href="a00096_source.html#l00244">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::getWeightSimilarity()</a>, <a class="el" href="a00098_source.html#l00066">mic::mlnn::fully_connected::HebbianLinear&lt; eT &gt;::HebbianLinear()</a>, <a class="el" href="a00099_source.html#l00068">mic::mlnn::fully_connected::Linear&lt; float &gt;::Linear()</a>, <a class="el" href="a00104_source.html#l00800">mic::mlnn::Layer&lt; float &gt;::serialize()</a>, <a class="el" href="a00104_source.html#l00307">mic::mlnn::Layer&lt; float &gt;::setOptimization()</a>, <a class="el" href="a00101_source.html#l00049">mic::neural_nets::unit_tests::Linear1x1Float::SetUp()</a>, <a class="el" href="a00089_source.html#l00066">mic::neural_nets::unit_tests::Conv2x2x2Filter2x1x1s1Double::SetUp()</a>, <a class="el" href="a00101_source.html#l00090">mic::neural_nets::unit_tests::Linear2x3Float::SetUp()</a>, <a class="el" href="a00089_source.html#l00137">mic::neural_nets::unit_tests::Conv3x3x2Filter3x2x2s1Float::SetUp()</a>, <a class="el" href="a00101_source.html#l00141">mic::neural_nets::unit_tests::Linear2x3Double::SetUp()</a>, <a class="el" href="a00101_source.html#l00190">mic::neural_nets::unit_tests::Linear50x100Double::SetUp()</a>, <a class="el" href="a00089_source.html#l00193">mic::neural_nets::unit_tests::Conv4x4x1Filter1x2x2s2Float::SetUp()</a>, <a class="el" href="a00089_source.html#l00261">mic::neural_nets::unit_tests::Conv4x4x1Filter3x1x1s3Double::SetUp()</a>, <a class="el" href="a00089_source.html#l00330">mic::neural_nets::unit_tests::Conv5x5x1Filter1x3x3s1Float::SetUp()</a>, <a class="el" href="a00089_source.html#l00381">mic::neural_nets::unit_tests::Conv5x5x1Filter1x2x2s3Float::SetUp()</a>, <a class="el" href="a00089_source.html#l00438">mic::neural_nets::unit_tests::Conv7x7x3Filter3x3x3s2Float::SetUp()</a>, <a class="el" href="a00089_source.html#l00521">mic::neural_nets::unit_tests::Conv5x6x1Filter1x4x4s1Float::SetUp()</a>, <a class="el" href="a00100_source.html#l00101">mic::neural_nets::unit_tests::TEST()</a>, <a class="el" href="a00102_source.html#l00098">mic::mlnn::fully_connected::SparseLinear&lt; eT &gt;::update()</a>, <a class="el" href="a00096_source.html#l00123">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::update()</a>, <a class="el" href="a00098_source.html#l00124">mic::mlnn::fully_connected::HebbianLinear&lt; eT &gt;::update()</a>, <a class="el" href="a00097_source.html#l00134">mic::mlnn::fully_connected::BinaryCorrelator&lt; eT &gt;::update()</a>, <a class="el" href="a00099_source.html#l00159">mic::mlnn::fully_connected::Linear&lt; float &gt;::update()</a>, and <a class="el" href="a00086_source.html#l00590">mic::mlnn::convolution::Convolution&lt; float &gt;::update()</a>.</p>

</div>
</div>
<a class="anchor" id="aca73ce8b130d8e5996aad367d6c86d48"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">mic::types::MatrixArray&lt;eT&gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::s</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>States - contains input [x] and output [y] matrices. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00753">753</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00086_source.html#l00449">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dW()</a>, <a class="el" href="a00086_source.html#l00335">mic::mlnn::convolution::Convolution&lt; float &gt;::backpropagade_dy_to_dx()</a>, <a class="el" href="a00102_source.html#l00075">mic::mlnn::fully_connected::SparseLinear&lt; eT &gt;::backward()</a>, <a class="el" href="a00084_source.html#l00082">mic::mlnn::activation_function::Sigmoid&lt; eT &gt;::backward()</a>, <a class="el" href="a00082_source.html#l00086">mic::mlnn::activation_function::ELU&lt; eT &gt;::backward()</a>, <a class="el" href="a00083_source.html#l00087">mic::mlnn::activation_function::ReLU&lt; eT &gt;::backward()</a>, <a class="el" href="a00093_source.html#l00124">mic::mlnn::cost_function::Softmax&lt; float &gt;::backward()</a>, <a class="el" href="a00099_source.html#l00126">mic::mlnn::fully_connected::Linear&lt; float &gt;::backward()</a>, <a class="el" href="a00099_source.html#l00289">mic::mlnn::fully_connected::Linear&lt; float &gt;::calculateMeanReconstructionError()</a>, <a class="el" href="a00086_source.html#l00054">mic::mlnn::convolution::Convolution&lt; float &gt;::Convolution()</a>, <a class="el" href="a00090_source.html#l00068">mic::mlnn::convolution::Cropping&lt; eT &gt;::forward()</a>, <a class="el" href="a00092_source.html#l00068">mic::mlnn::convolution::Padding&lt; eT &gt;::forward()</a>, <a class="el" href="a00109_source.html#l00071">mic::mlnn::regularisation::Dropout&lt; eT &gt;::forward()</a>, <a class="el" href="a00084_source.html#l00072">mic::mlnn::activation_function::Sigmoid&lt; eT &gt;::forward()</a>, <a class="el" href="a00083_source.html#l00072">mic::mlnn::activation_function::ReLU&lt; eT &gt;::forward()</a>, <a class="el" href="a00082_source.html#l00074">mic::mlnn::activation_function::ELU&lt; eT &gt;::forward()</a>, <a class="el" href="a00091_source.html#l00082">mic::mlnn::convolution::MaxPooling&lt; eT &gt;::forward()</a>, <a class="el" href="a00096_source.html#l00085">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::forward()</a>, <a class="el" href="a00093_source.html#l00094">mic::mlnn::cost_function::Softmax&lt; float &gt;::forward()</a>, <a class="el" href="a00098_source.html#l00095">mic::mlnn::fully_connected::HebbianLinear&lt; eT &gt;::forward()</a>, <a class="el" href="a00099_source.html#l00105">mic::mlnn::fully_connected::Linear&lt; float &gt;::forward()</a>, <a class="el" href="a00097_source.html#l00107">mic::mlnn::fully_connected::BinaryCorrelator&lt; eT &gt;::forward()</a>, <a class="el" href="a00104_source.html#l00165">mic::mlnn::Layer&lt; float &gt;::forward()</a>, <a class="el" href="a00086_source.html#l00186">mic::mlnn::convolution::Convolution&lt; float &gt;::forward()</a>, <a class="el" href="a00104_source.html#l00586">mic::mlnn::Layer&lt; float &gt;::getInputActivations()</a>, <a class="el" href="a00099_source.html#l00249">mic::mlnn::fully_connected::Linear&lt; float &gt;::getInverseOutputActivations()</a>, <a class="el" href="a00096_source.html#l00132">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::getOutputActivations()</a>, <a class="el" href="a00104_source.html#l00656">mic::mlnn::Layer&lt; float &gt;::getOutputActivations()</a>, <a class="el" href="a00096_source.html#l00157">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::getOutputReconstruction()</a>, <a class="el" href="a00096_source.html#l00202">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::getOutputReconstructionError()</a>, <a class="el" href="a00104_source.html#l00284">mic::mlnn::Layer&lt; float &gt;::getState()</a>, <a class="el" href="a00104_source.html#l00107">mic::mlnn::Layer&lt; float &gt;::Layer()</a>, <a class="el" href="a00104_source.html#l00199">mic::mlnn::Layer&lt; float &gt;::resizeBatch()</a>, <a class="el" href="a00104_source.html#l00800">mic::mlnn::Layer&lt; float &gt;::serialize()</a>, <a class="el" href="a00104_source.html#l00298">mic::mlnn::Layer&lt; float &gt;::setState()</a>, <a class="el" href="a00101_source.html#l00090">mic::neural_nets::unit_tests::Linear2x3Float::SetUp()</a>, <a class="el" href="a00101_source.html#l00141">mic::neural_nets::unit_tests::Linear2x3Double::SetUp()</a>, <a class="el" href="a00101_source.html#l00190">mic::neural_nets::unit_tests::Linear50x100Double::SetUp()</a>, <a class="el" href="a00088_source.html#l00033">mic::neural_nets::unit_tests::TEST()</a>, <a class="el" href="a00096_source.html#l00123">mic::mlnn::experimental::ConvHebbian&lt; eT &gt;::update()</a>, <a class="el" href="a00098_source.html#l00124">mic::mlnn::fully_connected::HebbianLinear&lt; eT &gt;::update()</a>, and <a class="el" href="a00097_source.html#l00134">mic::mlnn::fully_connected::BinaryCorrelator&lt; eT &gt;::update()</a>.</p>

</div>
</div>
<a class="anchor" id="a041b6dd9d22f6571f7e472e650935643"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; std::shared_ptr &lt;mic::types::Matrix&lt;eT&gt; &gt; &gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::x_activations</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Vector containing activations of input neurons - used in visualization. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00768">768</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00104_source.html#l00586">mic::mlnn::Layer&lt; float &gt;::getInputActivations()</a>.</p>

</div>
</div>
<a class="anchor" id="add0b5a4df52eb24e75d3a98395efae95"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename eT = float&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; std::shared_ptr &lt;mic::types::Matrix&lt;eT&gt; &gt; &gt; <a class="el" href="a00033.html">mic::mlnn::Layer</a>&lt; eT &gt;::y_activations</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Vector containing activations of output neurons - used in visualization. </p>

<p>Definition at line <a class="el" href="a00104_source.html#l00774">774</a> of file <a class="el" href="a00104_source.html">Layer.hpp</a>.</p>

<p>Referenced by <a class="el" href="a00104_source.html#l00656">mic::mlnn::Layer&lt; float &gt;::getOutputActivations()</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>src/mlnn/layer/<a class="el" href="a00104_source.html">Layer.hpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="a00149.html">mic</a></li><li class="navelem"><a class="el" href="a00153.html">mlnn</a></li><li class="navelem"><a class="el" href="a00033.html">Layer</a></li>
    <li class="footer">Generated on Sat Jan 26 2019 20:32:24 for MachineIntelligenceCore:NeuralNets by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.6 </li>
  </ul>
</div>
</body>
</html>
